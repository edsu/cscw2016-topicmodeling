{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: right; margin-right: 30px;\" src=\"https://cscw.acm.org/2016/images/logo@257px.png\">\n",
    "\n",
    "The following is a brief example of using [topic modeling](https://en.wikipedia.org/wiki/Topic_model) within a [Jupyter](http://jupyter.org) notebook. Jupyter is a web based programming and publishing environment that works with over 40 different programming languages.\n",
    "\n",
    "Since Jonathan and Karen went to [CSCW 2016](https://cscw.acm.org/2016/) a few weeks ago I thought it might be fun to try to use topic modeling to try to characterize the papers that were submitted there.\n",
    "\n",
    "I downloaded the PDFs for all 142 papers and converted them to text. Since the formatting was fairly structured I was also able to extract the abstracts from the text. You can see both the paper text and the abstracts in the [data](data) directory.\n",
    "\n",
    "I then wrote a bit of helper code using Python's [Gensim](https://radimrehurek.com/gensim/) topic modeling library to (hopefully) illustrate a little bit of how topic modeling works. The first thing we need to do is to import some of this helper code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from topicmodel import papers, abstracts, topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `papers` and `abstracts` functions are Python generators that return each word from each of the CSCW papers and abstracts. So for example we can see the words in the first abstract by calling the `abstracts` function and calling `next` on the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "next(abstracts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the text isn't pefect, but it's largely good enough for these purposes. We can then generate a topic model using the `topics` function. `topics` will create a [Latent Dirichlet Allocation](https://www.quora.com/What-is-a-good-explanation-of-Latent-Dirichlet-Allocation) model and then use the [Umass Topic Coherence](http://ciir-publications.cs.umass.edu/getpdf.php?id=956) algorithm to list the primary topics. I'll be the first to admit that I have little to no idea what that means. It's what the Gensim documentation told me. Perhaps Philip Resnick will have gone over some of this terminology beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topics(abstracts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are not very interesting because we mostly just see the most commonly ocurring words in most English text. However we can create a list (or really a Python set) of words to ignore when doing the modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = set([\"the\", \"of\", \"to\", \"a\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "And then we can call the `topics` function again, but this time passing in our list of words to ignore, which are usuall called *stop words*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topics(abstracts, ignore=words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But as you can see there are a lot more words that would be good to ignore. Luckily other people have run into this issue before and compiled lists of these extremely common English words, and I've included them here so we can import them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from stopwords import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how many words are in the list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we can try running `topics` again with this longer list of words to ignore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topics(abstracts, ignore=stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now finally things are getting a little bit more interesting! \n",
    "\n",
    "One important thing to note about LDA is that it is a *generative model* which uses *randomness* as part of the algorithm. So if we run `topics` again with the exact same options it will generate different results. How does this impact the way you might use topic modeling?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topics(abstracts, ignore=stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On inspection it looks like there words that are used a lot in CSCW papers that might be useful to add to our ignore list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords.add(\"social\")\n",
    "stopwords.add(\"work\")\n",
    "stopwords.add(\"study\")\n",
    "stopwords.add(\"paper\")\n",
    "stopwords.add(\"data\")\n",
    "stopwords.add(\"online\")\n",
    "stopwords.add(\"design\")\n",
    "stopwords.add(\"technology\")\n",
    "stopwords.add(\"users\")\n",
    "stopwords.add(\"media\")\n",
    "stopwords.add(\"people\")\n",
    "stopwords.add(\"results\")\n",
    "stopwords.add(\"content\")\n",
    "stopwords.add(\"information\")\n",
    "stopwords.add(\"systems\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topics(abstracts, ignore=stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point it might be useful to try to assign labels to some of the topic groups:\n",
    "\n",
    "1. **social media**: friends, inï¬‚uence, Likes, quality, provide\n",
    "2. **health**: support, health, present, research, mobile\n",
    "3. **community**: community, communities, present, network, interaction\n",
    "4. **online learning**: support, MOOCs, findings, sharing, video\n",
    "5. **privacy**: different, analysis, time, privacy, task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One very important thing to know about LDA topic modeling is that it is a generative statistical technique: it uses *randomness* as part of the algorithm. So if we run our `topics` helper function again with the exact same options we will get different results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topics(abstracts, ignore=stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does this randomness impact how you can use topic modeling as a tool in different problem domains?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `topics` helper function has some additional knobs you can turn to change the output. For example you can change the number of topics you would like to see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topics(abstracts, ignore=stopwords, num_topics=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And you can change the number of words in each topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topics(abstracts, ignore=stopwords, num_words=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember the `papers` generator we imported at the beginning? Well that contains all the text of the paper. Here's the text of the first paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "next(papers())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the papers through the LDA topic model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topics(papers, ignore=stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does looking at the fulltext of the paper change the modeling at all? Try playing around with the code if you want by adding stopwords, or changing the number of topics or words returned. \n",
    "\n",
    "That's all folks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
