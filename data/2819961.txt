CSCW '16, FEBRUARY 27–MARCH2, 2016, SAN FRANCISCO, CA, USA

YouthTube: Youth Video Authorship on YouTube and Vine 

Svetlana Yarosh 

University of Minnesota 

Minneapolis, MN 
lana@umn.edu 

Elizabeth Bonsignore 
University of Maryland 

College Park, MD 
ebonsign@umd.edu 

Sarah McRoberts 

Tamara Peyton 

University of Minnesota 

The Pennsylvania State University 

Minneapolis, MN 

mcrob021@umn.edu 

University Park, PA 
 tpeyton@psu.edu 

ABSTRACT 
What kinds of content do children and teenagers author and 
share on public video platforms? We approached this ques-
tion through a qualitative directed content analysis of over 
250  youth-authored  videos  filtered  by  crowdworkers  from 
public videos on YouTube and Vine. We found differences 
between YouTube and Vine platforms in terms of the age of 
the  youth  authors,  the  type  of  collaborations  witnessed  in 
the videos, and the significantly greater amount of violent, 
sexual,  and  obscene  content  on  Vine.  We  also  highlight 
possible  differences  in  how  adults  and  youths  approach 
online  video  sharing.  Specifically,  we  consider  that  adults 
may  view  online  video  as  an  archive  to  keep  precious 
memories  of  everyday  life  with  their  family,  friends,  and 
pets, humorous moments, and special events, while children 
and teenagers treat online video as a stage to perform, tell 
stories,  and  express  their  opinions  and  identities  in  a  per-
formative way. 
Author Keywords 
Child; teenager; authorship; online video; YouTube; Vine. 
ACM Classification Keywords 
H.5.1.  Information  interfaces  and  presentation  (e.g.,  HCI): 
Multimedia Information Systems: Video. 
INTRODUCTION 
In 2015, Frontline released “Generation Like,” highlighting 
how social media has changed the way children and teenag-
ers  connect  and  enact  identity,  which  has  in  turn  changed 
who  creates  the  content  that  influences  the  opinions  and 
practices  of  this  generation  [42].  Whereas  in  the  past, 
youth-targeted  content  was  authored  primarily  by  media 
giants such as Disney’s The Mickey Mouse Club and MTV, 
the  new  media  empire  increasingly  includes  content  au-
thored and shared by other children and teenagers [43,44]. 
What does youth video authorship and sharing look like in a 
generation where Internet fame may only be a single viral 
post  away?  We  contribute  to  answering  this  question  by 
investigating youth video authorship online, in the hope of 

Permission to make digital or hard copies of all or part of this work for personal or 
classroom use is granted without fee provided that copies are not made or distributed 
for  profit  or  commercial  advantage  and  that  copies  bear  this  notice  and  the  full 
citation on the first page. Copyrights for components of this work owned by others 
than  ACM  must  be  honored.  Abstracting  with  credit  is  permitted.  To  copy 
otherwise, or republish, to post on servers or to redistribute to lists, requires prior 
specific permission and/or a fee. Request permissions from Permissions@acm.org.
 CSCW '16, February 27-March 02, 2016, San Francisco, CA, USA  
© 2016 ACM. ISBN 978-1-4503-3592-8/16/02...$15.00  
DOI: http://dx.doi.org/10.1145/2818048.2819961 

informing the design of platforms that can foster creativity 
and  collaboration  around  online  video  content  while  still 
protecting  online  safety  and  privacy.  Additionally,  this 
work  contributes  to  an  important  thread  within  CSCW  on 
understanding  how  teenagers  and  young  adults  develop 
unique practices with social media, including videochat [9] 
and  instant  messaging  [17].  Revealing  the  differences  be-
tween  the  practices  of  teenagers  and  adults  can  highlight 
both generational and developmental differences in the use 
and attitudes to common social media technologies. 
We use an expanded definition of video author [10], as one 
having an active role in creating or contributing to the crea-
tion of original video content. Perhaps it is more helpful to 
specify  who  is  not  an  author  based  on  our  definition:  one 
who  simply  reposts  existing  content  without  change  (e.g., 
capturing a scene from a movie) or one who is unaware that 
the  video  is  being  created  (e.g.,  a  toddler  captured  in  the 
park in natural activity is generally not taking an active role 
in the creation of the video). We know a great deal about 
how adults author online video; for example, we know that 
18%  of  adults  post  original  content  on  online  platforms, 
such as YouTube and Vimeo [30]. We know that teenagers 
are comfortable using video as a communications medium 
to  “hang  out”  [9].  We  also  know  that  teenagers  are  fre-
quently active participants in online communities and social 
networking  sites  like  Facebook,  Snapchat,  and  Vine  [24]. 
However, we know very little about how children and teen-
agers  author  and  share  video  content,  despite  the  leading 
role  that  authors  as  young  as  seven  take  in  some  of  these 
communities [43]. In this paper we aim to address this gap 
by  answering  a  single  research  question:  What  kinds  of 
content do children and teenagers author and share on 
public video platforms? 
We answer this question by examining the videos children 
and  teenagers  make  publicly  available  on  YouTube  and 
Vine as primary sources of evidence. Through this content 
analysis  process,  we  contribute  not  only  a  novel  under-
standing of youth video authorship practices, but also artic-
ulate an effective approach to filtering relevant content au-
thored by a particular population of interest. 
We begin this paper with a brief overview of video sharing 
platforms, describing why we chose to focus this investiga-
tion on YouTube and Vine. We describe the related work in 
this  domain  to  help  articulate  our  contributions  both  in 
terms  of  the  findings  of  our  study  and  the  particular  ap-
proach we take to filtering relevant content. We briefly de-
scribe a situating study looking at parents’ understanding of 

1423

their  children’s  online  video  sharing  practices,  before  dis-
cussing the methods and findings of our content analysis of 
youth-authored  online  video.  We  end  with  a  discussion 
highlighting unique aspects of Vine as a platform, a com-
parison of the differences in use of video platforms between 
youths  and  adults,  and  a  reflection  on  our  methodological 
approach. 
VIDEO SHARING PLATFORMS 
There  are  many  platforms  and  communities  that  support 
video sharing: 
•  YouTube  is  the  largest  community  for  sharing  video 
content online. It has no genre constraints or time lim-
its and provides billions of public, searchable videos. 

•  Twitch  hosts  a  large  collection  of  public  videos  fo-
cused  on  live-streaming  of  video  games  including 
game tournaments, screencasts, and play-throughs. 

•  Vine  is  a  public  video-sharing  platform  owned  and 
operated  by  Twitter  and  best  known  for  its  6-second 
time limit. 
Instagram began as a photo-sharing platform but has 
recently expanded to support short (3-15 second) video 
shares. 

• 

•  Snapchat  is  an  app  that  provides  mobile  picture  and 
video sharing with a particular feature of content “ex-
piring” after a certain time period. Public sharing is en-
abled through the story feature, which displays a shared 
video or photo for only 24 hours. 

•  Facebook is a general-purpose social networking site. 
It allows sharing videos and photos with different pri-
vacy settings. 

While all of these are popular with children and teenagers 
[24], we chose to focus on YouTube and Vine as the two 
most  popular  platforms  where  public  video  sharing  is  the 
primary purpose. 
RELATED WORK 
Our  work  is  situated  in  previous  investigations  of  public 
video  sharing  platforms  and  understanding  and  parenting 
online  practices  of  teenagers,  but  we  contribute  a  novel 
understanding  of  youth-video  authorship  practices.  While 
our  efforts  are  methodologically  influenced  by  work  that 
filters and analyzes videos of specific populations of inter-
est, we also contribute a new approach to filtering relevant 
content. 
Understanding Public Video Sharing Platforms 
We are not the first to investigate public video sharing plat-
forms like YouTube and Vine. For example, Pew Research 
Internet  Project  conducted  a  large-scale  survey  of  online 
video in 2013 to find that 18% of adult users author videos 
and post them online [30]. From this large scale study, we 
know  that  adult  authors  most  commonly  post  videos  of 
family  and  friends  doing  everyday  things  (58%  of  the  au-
thors), themselves or others doing funny things (56%), and 
events  they  attend  (54%)  [30].  Ding  et  al.  examined 
YouTube  authorship,  finding  that  while  YouTube  hosts  a 

1424

SESSION: MUSEUMS AND PUBLIC SPACES

massive  number  of  contributors,  63%  of  the  most  popular 
uploaders  were  primarily  sharing  user-copied  (rather  than 
user-authored)  content  [11].  Looking  more  closely  at  spe-
cific user-authored content, Biel and Gatica-Perez’ investi-
gation examined specific media characteristics of user vlogs 
and  how  they  correlate  with  popularity  [8].  Farnham  and 
Churchill suggest that people maintain faceted lives online, 
choosing identity presentation based on the affordances of 
various technologies [12]. Finally, Rotman et al. enhanced 
our  understanding  of  what  motivates  people  to  contribute 
content to YouTube through a mixed-method investigation 
of  perceived  community  and  sense  of  belonging  on  this 
platform [33]. Despite the fact that we know that age affects 
authorship in online video communities [30], none of these 
studies  examined  youth  authorship  on  video  sharing  plat-
forms. 
Vine has been investigated considerably less than YouTube, 
though we know that a quarter of teenagers have Vine ac-
counts  [24].  Zhang  et  al.  quantitatively  examined  repost 
traces  of  over  50,000  video  clips  and  1,000,000  user  pro-
files  on  Vine,  showing  that  this  platform  is  distinct  from 
others  in  several  ways,  such  as  encouraging  unique  batch 
viewing practices and exhibiting an unusually strong skew 
in  the  distribution  of  views,  with  the  top  5%  video  clips 
accounting for more than 99% of all reposts [41]. However, 
neither  of  the  above  investigations  examined  video  post 
content. Although Vine has been identified as an important 
part of the research agenda for understanding video interac-
tion [23], we are one of the first to examine the content of 
the videos shared through this platform. 
Understanding  Parenting  of  Children’s  and  Teenagers’ 
Online Practices 
Studies of children’s and teenagers’ use of social network-
ing  and  online  sharing  platforms  have  largely  focused  on 
parenting  and  privacy  practices  online.  For  example, 
through  over  100  semi-structured  interviews  with  parents, 
we know that that many parents carefully consider, curate, 
and shape their children’s online presentation [4]. Another 
paper in this series of studies has also identified a number 
of  rules  and  practices  that  parents  have  for  limiting  their 
children’s  online  presence  [40].  However,  these  studies 
may have been limited in their findings by not including the 
voices of the children or teenagers, since other studies have 
pointed out that parents generally have fairly limited insight 
of  their  children’s  online  practices  [35].  Other  qualitative 
interview work in this space included teenagers in the con-
versation about parenting and online privacy practices, find-
ing  that  parents’  and  teenagers’  practices  and  values  fre-
quently did not coincide, but were moderated by the moral 
development level of the child [39]. Large scale investiga-
tions, like Pew Internet Research surveys with both parents 
and  children  around  privacy  practices,  found  that  going 
outside parental guidelines was not always negative, as ado-
lescent risk taking online can be related to the development 
of coping mechanisms and resilience to negative outcomes 
[32,37,38]. From this body of work it is clear that children’s 

CSCW '16, FEBRUARY 27–MARCH2, 2016, SAN FRANCISCO, CA, USA

and teenagers’ online sharing activities are important both 
for  parenting  practices  and  in  the  process  of  growing  up 
online;  however,  parents’  and  children’s  perceptions  and 
practices  frequently  differ.  While  parents  are  concerned 
with  online  safety  across  emotional,  physical,  and  social 
dimensions, the challenge is to create spaces that still allow 
the flexibility for children and teenagers to learn their own 
risk management strategies, and to negotiate social conflict 
in positive ways [22,32].   
Inspired by this work with parents, we began our investiga-
tion  with  a  situating  study  of  parenting  practices  around 
youth video authorship. Ultimately, however, we found that 
the primary source of videos authored by youths themselves 
was  a  richer  source  of  evidence  about  their  online  video 
creation practices. 
Using YouTube as a Primary Data Source 
We  are  not  the  first  researchers  to  leverage  public  video 
sharing platforms as a primary source of data in understand-
ing a specific population. For example, Anthony et al. gath-
ered and analyzed videos of technology use by people with 
motor impairments by combining disability- and technolo-
gy-related  search  terms  [5].  More  recently,  a  similar  ap-
proach of combining demographic- and technology-related 
search  terms  was  taken  by  Hourcade  et  al.  to  understand 
infants’  and  toddlers’  use  of  tablet  devices  [19].  This  ap-
proach has also been applied to the health domain, for ex-
ample  by  Liu  et  al.  who  analyzed  health  video  blogs  on 
YouTube by searching for vlogs relating to specific health 
conditions (i.e., diabetes, HIV, cancer) [26]. While we were 
inspired  by  these  techniques,  our  initial  attempts  to  repro-
duce them showed that a keyword-based search would not 
work well for identifying youth-authored videos for analy-
sis, since authorship information was generally not included 
in  the  title,  keywords,  or  description  of  the  video,  and  al-
most no people populate their demographic information in 
the bio. One of the contributions of this work is articulating 
an alternative process for filtering relevant video data when 
available search terms do not generate an adequate data set. 
Approaches  to  Understanding  Specific  Populations’ 
Use of Public Video Platforms 
Previous  investigations  have  taken  four  approaches  to  un-
derstand  specific  populations’  use  of  public  video  plat-
forms.  We  go  through  these  below  to  articulate  how  our 
approach builds on and contributes an alternative to previ-
ous work. 
One approach to understanding a specific population’s use 
of  public  video  platforms  is  to  follow  a  specific  group  of 
participants  in  a  target  demographic  and  observe  their  use 
(if any). For example, Sayago et al. followed a group of 32 
elderly  study  participants  to  understand  their  technology 
use, including whether, when, and how they used YouTube 
[34]. Unfortunately, this may not work for sparse examples 
of use, for example, if only a few members of the popula-
tion of interest author video content.  

Another approach to understanding a specific population is 
identifying and analyzing media that may be of special in-
terest to that population. For example, Asselin et al. investi-
gate  student  discussions  around  online  educational  videos 
[6], focusing on educational videos and channels identified 
by soliciting the advice of educators in the field. However, 
when the relevant types and topics of content are unknown 
(or are in fact the research question, as here), this method 
does not work.  
A third approach is large-scale survey sampling of the tar-
get population. For example, the Pew Research Center re-
port on Teens, Social Media, & Technology surveyed over 
one  thousand  teenagers  to  find  that  52%  of  them  reported 
using  Instagram,  41%  used  Snapchat,  and  24%  used  Vine 
[24]. However, this does not support a rich analysis of con-
tent and practices in the use of these platforms. For exam-
ple,  we  do  not  know  how  each  of  these  is  used,  such  as 
whether  teenagers  were  authoring  content  on  these  plat-
forms  and  what  type  of  content  was  being  authored  and 
shared.  
Lastly, this work was influenced by the automatic content 
filtering approach to identifying a relevant population, pro-
posed  by  Jang  et  al.  in  their  analysis  of  teenagers’  use  of 
Instagram  [21].  To  compare  the  Instagram  accounts  of 
adults  and  teenagers,  they  searched  through  text  descrip-
tions of age for cases when somebody stated age in their bio 
and  utilized  the  age  analysis  characteristics  of  the  Face++ 
face recognition API on the profile photos. However, they 
found  that  the  API  struggled  with  detecting  teenagers  and 
the data required some by-hand validation. This is an excel-
lent  example  of  a  situation  where  human  intelligence  is 
capable of combining diverse evidence (e.g., photo, video, 
voice,  text)  to  make  a  more  coherent  determination  of  a 
person’s age than would be possible by a machine. Inspired 
by this idea, our work contributes a crowdsourcing method 
for identifying and filtering relevant youth-authored content 
on public video sharing platforms. 
SITUATING PILOT STUDY: PARENTS’ PERCEPTIONS 
OF YOUTH ONLINE VIDEO AUTHORSHIP 
Similar to other studies in this domain (e.g., [40]), we began 
our work by reaching out to parent for useful insights about 
family rules regarding their children’s online video practic-
es. To do so, we conducted a situating pilot study through 
an  online  questionnaire  of  parents.  We  present  this  study 
here in the interest of sharing an approach that didn’t work 
with the community, as revealing unsuccessful approaches 
frequently offers value to other researchers. 
Parent Questionnaire Methods 
Our  online  questionnaire  targeted  parental  attitudes  and 
beliefs about their own children’s video-authoring practic-
es. We reached out to parents of children between the ages 
of 7 and 17 who post videos online. We gathered basic de-
mographic  information  and  asked  parents  how  frequently 
their  children  make  videos,  the  technology  and  sites  that 
children use in the process of creating and sharing the vide-

1425

os,  and  their  family  rules  and  practices  around  children’s 
video  sharing.  We  promoted  the  online  questionnaire 
through a paid Google Adwords advertisement, a paid tar-
geted  Facebook  promotion  campaign,  and  through  social 
media  and  word-of-mouth  by  the  research  team.  The  re-
spondents  were  offered  a  chance  to  enter  a  drawing  for  a 
retail  gift  card  in  exchange  for  their  completed  question-
naire. A total of 54 responses were recorded though only 18 
were  validated  as  relevant  for  this  study  (i.e.,  responses 
where parents knew about and were able to articulate their 
children’s  video-authoring  practices).  Due  to  this  small 
number  of  relevant  responses,  we  focus  on  the  overall  in-
sights and qualitative findings from this process. 
Parent Questionnaire Results 
When  asked  about  family  rules  around  video-authorship, 
most parents (61%) responded that their children controlled 
their video-authorship appropriately on their own, suggest-
ing little need for direct supervision or oversight. However, 
in discussing specific rules or practices, parents frequently 
suggested  that  they  did  have  rules.  For  example,  72%  of 
parents  reported  allowing  their  child  to  show  their  videos 
only to family and known friends, though they also reported 
that these videos were shared or uploaded via YouTube or 
Snapchat. For videos that were allowed to be public, there 
seemed  to  be  a  common  rule  of  allowing  the  child  to  use 
their voice in a video but not allowing a child to show their 
own  face  or  the  face  of  other  family  members  or  family 
environments in the videos. A few respondents mentioned 
that they do not monitor their children’s video sharing hab-
its, but do give them behavioural guidelines. For example, 
two participants described these rules as:  

No swear words, nudity, etc. They must follow what I consider 
to be normal human behaviour as if they were in public and 
everybody can see them ... I keep a fairly strict set of rules for 
my daughters. 
Act appropriately—meaning nothing violent, no bad language, 
etc. Basically, the same way they are expected to act at home 
or in class. Also, no identifiable information in the videos, like 
their names. 

However, several parents also reported catching their chil-
dren  posting  videos  that  violated  the  guidelines  set  for 
them: 

Along with his brother and cousin, my son recorded a screen-
cast of Sid the Science kid with them doing rude voice-overs in 
the  style  of  YouTube  Poops.  Then  he  uploaded  it  with  rude 
language in subtitles ... When I discovered this video I asked 
him to remove it and [not] create or upload videos like it, with 
"inappropriate" language or behaviour. 
[The video] was a "let's play" of a game that I didn't want him 
playing because I felt it was too violent. 

These comments suggest that there may be interesting vid-
eo-authorship  practices  happening  outside  of  parental  su-
pervision.  
 

1426

SESSION: MUSEUMS AND PUBLIC SPACES

Parent Questionnaire Discussion 
Though this research team has significant experience work-
ing with parents and families, we found that it was unusual-
ly difficult to recruit for this project. We found that many 
parents were unaware of or unwilling to discuss their chil-
dren’s  online  video  practices.  Though  we  asked  questions 
about specific content posted, few parents opted to specify 
what  their  children  posted  online  or  discuss  examples  of 
their children’s video. 
The results from this questionnaire led us to doubt whether 
parents were entirely aware of their children’s online video 
practices. For example, while previous studies show that a 
quarter  of  teenagers  use  Vine  [24],  none  of  the  parents  in 
the  questionnaire  mentioned  this  platform.  Additionally, 
many  parents  mentioned  comprehensive  rules  regarding 
their  children’s  video  sharing  such  as  not  showing  faces, 
inappropriate dress, and inappropriate language. In contrast, 
even a casual examination of video sharing services reveals 
many videos do not follow these rules. Indeed, this is con-
sistent with previous work that shows that parents may have 
limited  insight  into  the  children’s  online  experiences  [35]. 
Our main take-away from this situating study was that ask-
ing  parents  was  not  a  good  approach  for  identifying  and 
understanding  youth  video  authorship  practices.  While  the 
situating study was helpful in revealing some family rules 
that  some  families  have  around  video  sharing,  to  address 
our  primary  research  question  about  the  content  of  shared 
videos we turned to publicly shared video content as a pri-
mary source of evidence on youth-authored video. 
CONTENT ANALYSIS STUDY: YOUTH AUTHORSHIP ON 
YOUTUBE AND VINE 
The preliminary study with parents left us with more ques-
tions  than  answers  about  youth  online  video  practices,  so 
we decided to examine publicly-shared videos as the prima-
ry  source  of  evidence  for  content  created  and  shared  by 
children and teenagers. Below, we describe the process of 
identifying  youth-authored  video  and  conducting  the  con-
tent analysis, as well as our findings from this process. 
Identifying Youth-Authored Video 
We identified a set of youth-authored videos by using Am-
azon Mechanical Turk to categorize the evident authorship 
of thousands of recently shared videos from YouTube and 
Vine. 
Gathering the Initial Video Set 
To  identify  the  most  promising  sources  for  the  video  data 
set, we gathered an initial set of 50 most recently posted (as 
collected in August 2014) public videos per YouTube cate-
gory  and  100  most  recent  Vine  videos  shared  on  Twitter. 
Recent videos were chosen as the most equivalent way of 
getting a “random” set of videos from YouTube and Vine. 
While the YouTube API provides no way to get “random” 
videos, we can get those posted within a certain time peri-
od. We chose “most recent” because Vine does not provide 
an API, so we could only collect recently shared videos by 
setting  up  an  hourly  script.  Three  researchers  looked 

CSCW '16, FEBRUARY 27–MARCH2, 2016, SAN FRANCISCO, CA, USA

through these videos, tagging those that were likely to have 
been  posted  by  a  minor  (e.g.,  child  on  camera,  child’s 
voice, etc.). Using this approach, we created initial filtering 
mechanisms such as excluding YouTube categories that did 
not  feature  at  least  one  child  video  out  of  the  50  videos 
viewed  (e.g.,  “Gaming”  was  included,  “News  &  Politics” 
was not). This piloting process also helped us develop intui-
tions and conventions for structuring the Amazon Mechani-
cal Turk HIT to scale up the filtering process (described in 
the next section). 
Once we developed these categories, we used the YouTube 
API  and  Twitter  API  to  collect  a  data  set  of  about  5000 
recently posted videos from YouTube and another 5000 of 
unique  recently  shared  videos  from  Vine.  We  collected  a 
larger set of videos than we anticipated we would need, to 
account for videos being removed and to be able to expand 
our analysis as needed. This proved warranted as we origi-
nally analyzed 1000 videos from each category, but finding 
that  YouTube  had  a  considerably  lower  rate  of  relevant 
videos, we selected an additional set of 2000 YouTube vid-
eos from our gathered data set to analyze. One limitation of 
our approach is that recently tweeted videos are more likely 
to  include  popular  videos  than  recently  posted  videos  on 
YouTube; however no equivalent of “most recently posted 
videos” exists on Vine. For this reason, we conducted and 
report the analysis of YouTube videos and Vine videos sep-
arately. Once this initial set was gathered, we proceeded to 
filter videos that were authored by children and teenagers. 
Filtering Youth-Authored Video 
Amazon’s  Mechanical  Turk 
flexible 
crowdsourcing service that enables various types of human 
computation, or the use of a human workforce to complete 
tasks that people can tackle better than computers [31]. In-
dividuals and organizations called Requestors post short (as 
short as 10 seconds) HITs (human intelligence tasks). Indi-
viduals  who  respond  to  these  tasks  are  Turkers,  and  are 
compensated in small amounts of money (as low as $0.01 
per  HIT).  In  addition  to  labeling  images,  typical  tasks  in-
clude  sentiment  analysis  of  text,  writing  product  reviews, 
and transcribing audio [25]. Our goal for employing MTurk 
was to filter a manageable set of youth-authored content for 
in-depth content analysis from the large sample of YouTube 
and  Vine  videos  that  we  had  collected  through  our  first-
level filtering. 
The default MTurk Requester UI offers a set of basic tem-
plates for creating HITs, such as a categorization template 
[2]. Based on our review of the initial set of 50 videos, we 
knew that we needed to include a confidence value or quali-
fier  about  the  age  of  video  authors.  For  example,  some 
teens looked older than the ages they posted on their public 
profiles,  and  determining  age  without  explicit  profile  data 
like this is a subjective process. MTurk’s default categori-
zation template did not afford us such qualifiers, so we im-
plemented a modified HIT using the MTurk Command Line 
Interface (CLI) [3].  

(MTurk) 

is  a 

 

Vine 

 

YouTube 

 
  120   (4.0%) 
    24   (0.8%) 
2838 (94.6%) 

114 (11.3%) 
  89   (8.9%) 
797 (79.7%) 

T1 & T2 both assign 4 
T1 & T2 both assign 3 or 4 
T1 & T2 rate other   
Table 1. Summary of Turker ratings (T1 = Turker1 rating; T2 
=  Turker  2  rating),  focusing  on  those  identified  as  youth-
authored,  some  collaboration  of  youth  and  adult,  and  non-
youth-authored. 
We defined our HIT so that Turkers could identify five dif-
ferent categories of authorship, along with a rating qualifier 
 
that  they  could  select  if  they  felt  their  age  judgment  was 
“borderline” (i.e., the video creator might be 20 years old, 
instead  of  a  teenager).  We  defined  our  video  authorship 
rating categories as follows: 
•  Rating category 0: There is ZERO evidence about the 
video creator’s age in the video (no voice, no face, etc.) 
or video description. 

 

•  Rating category 1: This video does not appear to in-

volve a minor. That is, only adults are shown, or it ap-
pears to be a professional/company-created video. 

•  Rating category 2: This video appears to involve a mi-
nor, but not as its primary creator – e.g., a parent film-
ing a toddler playing in the park. 

•  Rating category 3: This video appears to involve some 

collaboration between adult and children/teenagers – 
e.g., a parent may be recording or may host the video, 
but the child is directing the action. 

•  Rating category 4: This video appears to be authored 

by a child or teenager. 

We introduced the rating system as follows: 

Review  and  rate  the  video  in  the  link  provided  based  on 
whether  you  can  tell  if  a  minor  (youth  under  18  years  old) 
created the video, or was involved in its creation in some way. 
….  If  you  cannot  tell,  or  see  no  evidence  anywhere  that  the 
video was created by a minor, select the “Zero Evidence” op-
tion.  

To mitigate any concerns of Turkers about our reasons for 
seeking out videos of and/or created by minors, we included 
a description of our IRB-approved research at the bottom of 
the  HIT  instructions:  “This  work  is  part  of  an  approved, 
academic research study on digital media created by youth. 
University researchers are conducting a study that focuses 
on  the  types  of  videos  that  youth  (younger  than  18  years 
old) create and share online.” 
Beyond the typical MTurk requester issue of defining a HIT 
clearly so that it is easily understood and quickly taken up 
by Turkers, requesters typically face two challenges in de-
veloping effective HITs [31]:  
•  Ensuring  quality  control  and  accuracy  of  HIT  results 
without  incurring  any  excessive  overhead  for  double-
checking work; and 

•  Providing sufficient incentive/motivation for reputable 

1427

SESSION: MUSEUMS AND PUBLIC SPACES

Turker redundancy, coupled with high approval ratings and 
our  own  by-hand  checks  of  the  videos  rated  3s  and  4s, 
would  still  yield  reliable  results,  so  we  opted  to  allow 
Turkers who may have had less experience, but consistently 
high  approval  ratings.  As  the  study  progressed,  we  found 
that very few videos were miscoded (only 5% and always 
with the “uncertain” of age qualifier added). This low error 
rate  increases  our  confidence  in  the  validity  of  the  Turker 
responses. 
To address the incentive challenge, we estimated the time to 
complete an individual rating based on our experience iden-
tifying authorship in our initial set of 50 videos, surveyed 
compensation averages offered for comparable HITs in the 
MTurk  community,  and  reviewed  Amazon’s  Requestor 
“Best Practices.” We estimated that a HIT would take ap-
proximately  60  seconds  to  complete;  however,  to  give 
Turkers  ample  time  to  review  videos,  we  set  a  maximum 
time of 5 minutes per hit. We also settled on an average of 
$0.18  payment  per  approved  HIT  (MTurk  requestors  can 
choose to disapprove payment if a Turker consistently pro-
duces low quality work). Qualified Turkers rated the 4000 
videos  within  48  hours  of  launching  our  assignment  (at  2 
Turkers  per  video,  we  coordinated  8000  HITs).  Turkers 
took an average of 55 seconds to complete each HIT, con-
firming  our  estimate.  We  conducted  random  QC  of  com-
pleted  HITs,  checking  approximately  120  video  ratings 
(3%), and approved all completed HITs. Based on the com-
pletion rate and overall quality of our results, we found that 
our MTurk-based filtering process is an effective alternative 
method for identifying and filtering youth-authored content 
on public video platforms. 
Turker Results and Follow-Up Process 
Results of our MTurk filtering process are shown in Table 1 
and Figure 1. Table 1 provides the number of videos identi-
fied  as  youth-authored  for  each  video-sharing  platform. 
Overall, Turkers identified youth-authored videos in about 
9.1%  of  our  total  sample  of  videos  (365  of  4000  in  raw 
numbers). Beyond the ratings shown in Table 1, we found 
that the age-qualifier that we included in our HIT was use-
ful  at  highlighting  videos  that  might  need  to  be  reviewed 
more closely or dropped from our in-depth analysis count. 
Figure 1 displays our Turker rating results as a breakdown 
of  most  likely  youth-authored  (both  Turkers  assigned  the 
video  a  category  4  rating);  youth-authored  or  youth/adult 
collaboration (one Turker identified the video as category 4, 
while the other identified it as category 3, or a collaboration 
between  youth/adult);  or  most  likely  a  collaboration  (both 
Turkers assigned a category 3 rating). The figure also high-
lights  the  number  of  videos  within  each  category  that 
Turkers qualified their rating as one where “author is possi-
bly  older,  or  borderline  age  than  18  years  old.”    Stacked 
within each bar, the lighter shade reflects those videos for 
which Turkers felt the author might be a young adult (19-21 
years old) versus a minor (younger than 18). Turkers quali-
fied their ratings 30-40% of the time.  

 
Figure 1. Breakdown of videos that Turkers identified as sole-
ly youth-authored (rating 4), either youth-authored or possibly 
a youth/adult collaboration (rating 3 or 4) or likely a collabora-
tion  (rating  3).  The  bars  reflect  those  that  were  identified  as 
“borderline” – i.e., author might be older than 18-years old. 

Turkers to apply to complete their HITs. 

To  address  quality  control  (QC),  we  included  two  QC 
measures [31] into our MTurk filtering process:  
•  Reputation: Only Turkers who met our qualification 

requirements were eligible; and, 

•  Redundancy: Two Turkers were assigned to each HIT, 
as a redundancy for selecting our subset of videos for 
in-depth content analysis. 

In order to recruit high-quality Turkers who understood our 
video authorship identification task and could be reasonably 
expected to make “good” ratings about authorship, we de-
veloped a video-rating qualification test. Qualification tests 
are a “gold standard,” or ground truth that reputable Turkers 
can  earn  to  become  eligible  to  complete  more  HITs  and 
gain  increased  reputation  in  the  MTurk  crowdsourcing 
community. For requestors to implement qualification tests, 
they must use the MT Command Tool API (the default MT 
Requester UI templates do not include options for including 
a gold standard qualification test) [2]. To be eligible to ac-
cept  our  video-authorship  HITs,  Turkers  first  had  to  be 
identified as reputable in the MTurk community, based on 
earning a 95+% approval rate for HITs they had completed; 
and also complete our video-rating qualification test with a 
minimum score of 88%. We wanted to balance the number 
of  qualifications  required  for  our  HITs  and  the  number  of 
Turkers who were eligible, while maintaining a fairly high 
level  of  quality  in  our  results.  We  determined  that  two-

1428

CSCW '16, FEBRUARY 27–MARCH2, 2016, SAN FRANCISCO, CA, USA

Ethical Considerations 
While  this  process  examined  only  publicly  shared  videos, 
we carefully considered the ethical implication of studying 
and sharing these videos outside of their originally intended 
context. We carefully considered the balance of presenting 
our original data to support reinterpretation and reanalysis 
by the scientific community with the potential harms such 
presentation could bring to video authors. In order to pro-
tect the authors we take four steps. First, we only share vid-
eos that have already gathered a large audience (e.g., over 
10,000  views),  as  we  are  unlikely  to  be  introducing  new 
unanticipated risks to those authors. Second, instead of ar-
chiving these examples, we include direct links to the pub-
lic videos. This means that these links will only remain val-
id  for  as  long  as  the  authors  choose  to  keep  their  videos 
public.  We  respect  the  creators’  right  to  remove  videos  at 
any time. Third, all video creators were contacted to inform 
them we were linking the video and to give them an oppor-
tunity to opt out (none chose this option). Finally, all video 
screen captures are traced to remove identifiable features. 
Content Analysis Process  
The  content  analysis  included  two  components:  gathering 
posted  data  for  each  video  and  author  (e.g.,  video  views, 
video  description)  and  data-driven  content  analysis  where 
each  video  was  viewed  and  analyzed  by  at  least  one  re-
searcher.  To  gather  posted  data  from  the  YouTube  videos 
and about the YouTube users, we used the YouTube API. 
Since no similar Vine API is available, we used Selenium 
and BeautifulSoup to scrape the posted information directly 
from  the  Vine  video  and  user  pages.  The  analysis  of  this 
data is presented in the following section. 

 

However,  most  of  the  in-
formation  that  was  of  inter-
est to our research questions 
was  not  posted  directly  to 
the  video  and  had  to  be 
hand-coded.  In  order  to  ar-
rive  at  a  consistent  set  of 
coding  practices,  we  ran-
domly  selected  and  inde-
pendently  coded  20  videos 
from the filtered data set of 
youth-authored  video.  This 
Figure 2.  Using our descrip-
four-rater agreement process 
tion schema, this video is de-
was  done  on  a  randomly 
scribed as “Two teenage boys 
act in a parody skit of a Pop-
selected  subset  of  videos 
eye’s commercial on a subur-
rather  than  the  entire  video 
ban street.” 
set to calibrate our practices 
https://vine.co/v/MDAnu39pP2W 
and  is  considered  an  appro-
priate  way  of  establishing 
 
inter-rater reliability and consistency [18]. This independent 
coding  process  included  quantitative  characteristics  (e.g., 
estimated  age  of  author),  binary  ones  (e.g.,  is  the  child’s 
face visible), and qualitative ones (e.g., open coded descrip-
tion of the video content). On the 20 videos, the four inde-
pendent coders had strong agreement (Krippendorff’s alpha 

1429

= 0.83) on quantitative characteristics such as the estimated 
age  of  the  minors  involved.  We  had  perfect  agreement 
(Krippendorff’s  alpha  nominal  =  1)  on  binary  characteris-
tics such as whether the youth’s face is visible or voice au-
dible in the video. To compare our qualitative descriptions 
of the videos, one researcher pulled out 2–4 main keywords 
from each coder’s open coded description. There was sig-
nificant agreement between the coders as to the contents of 
each video, with 80% of keywords (or synonyms) appear-
ing in all four raters’ descriptions. We discussed disagree-
ments  and  decided  how  to  best  focus  our  qualitative  de-
scription  of  other  videos.  We  developed  a  description 
schema  for  the  remaining  open  coding  to  ensure  that  we 
included  all  pertinent  characteristics  of  the  video:  “[Per-
son(s)] [action] [of/about object] [if visible: location]” (see 
Figure 2 for an example). These descriptions served as tex-
tual  data  that  we  could  cluster,  use  for  axial  analysis,  and 
leverage  to  refer  to  specific  videos  as  we  considered  new 

Vine Videos 

 

% Deleted 3 Mo. Later 
Mdn. # Loops 
Mdn. # Likes 
Mdn. # Comments 

Youth  
(n=205) 
10.7% 

1,433,000 
23,300 
1,370 

Youth  
(n=126) 
14,600,000 

Non-Youth 

(n=749) 
7.4% 
985,000 
12,500 
758 

Non-Youth 

(n=544) 
12,100,000 

Vine Users 

17,800 

25,600 
121 

Mdn. # Loops 
Mdn. # Followers 
Mdn. # Following 
99 
Table 2. Scraped characteristics comparing Vine videos 
marked by Turkers as youth-authored versus other videos on 
median characteristics of viewership (median was chosen be-
cause of the significant skew in this sample, reported in previ-
ous investigations of online video sharing). 
 

YouTube Videos 

Youth 
(n=131) 

Non-Youth 
(n=2743) 

 
Mdn. # Views 
Mdn. # Likes 
Mdn. # Dislikes 
Mdn. # Comments 
%Deleted 3 Mo. Later 

88 
3  
0 
2 

1,700 
27 
4 
73 

13.9% (from 
original n=37) 

9.7% (from origi-

nal n=846) 

YouTube Users 

Youth 
(n=127) 

Non-Youth 
(n=1472) 

225 

122 

100,000 

27 
3531 
20 

Mdn. # Videos 
Mdn. # Views 
Mdn. # Subscribers 
Table 3. Scraped characteristics comparing YouTube videos 
marked by Turkers as youth-authored versus other videos on 
median characteristics of viewership (median was chosen be-
cause of the significant skew in this sample, reported in previ-
ous investigations of online video sharing). Percent of videos 
deleted 3 months after MTurk ratings is only of the first batch 
of videos evaluated. 
 

categories of video content. 
After  this  coding  calibration  and  discussion  process,  the 
remaining set of youth-authored videos was divided among 
the four researchers and open coded. Additionally, through-
out  this  coding  process,  researchers  culled  the  data  set  of 
any videos that did not fit our criteria, for example ones that 
were posted in curated collections rather than by individual 
contributors, and ones that were not original (e.g., captures 
TV show, batched upload with duplicate videos). This con-
stituted  6%  of  the  videos  and  they  were  removed  prior  to 
additional coding. Additionally, we reevaluated some cases 
where the Turker were unsure of their estimates of author 
ages;  if  two  researchers  agreed  that  the  video  author  was 
older than 20, it was excluded from the data set (this consti-
tuted 5% of the videos rated as 3 or 4 by both Turkers). The 
culled  data  set  consisted  of  131  YouTube  youth-authored 
videos and 148 Vine youth-authored videos (279 total). 
Once we culled and open-coded the video list, we conduct-
ed another round of coding to cluster videos into categories 
of  content.  Since  significant  prior  work  already  exists  on 
video  authorship  practices  (e.g.,  [30]),  we  opted  for  a  di-
rected rather than conventional qualitative content analysis 
of  video  content.  While  conventional  content  analysis  is 
entirely  inductive,  a  directed  content  analysis  combines  a 
deductive approach of coding for categories observed in the 
previous literature with an inductive approach for identify-
ing new categories if any appear in the data (for more detail 
on  directed  content  analysis,  see  Hsieh  &  Shannon  [20]). 
Thus,  we  deductively  assigned  seven  of  the  author-
generated  content  categories  (top  7  in  Figure  4)  identified 
by the Pew Internet Report on Online Video [30]. But, as 
we  expected  this  list  to  be  incomplete  for  youth  authored 
video, we also conducted data-driven analysis of the open-
coded description schema to identify additional and missing 
categories. The inductive analysis was conducted through a 
process  of  open  coding  descriptions  of  videos,  memoing, 
and axial coding until relevant categories emerged from the 
data. As we arrived at our final set of categories (Figure 4), 
we conducted closed coding of the data set. Again, we ran-
domly  selected  a  subset  of  videos  (30  videos)  that  were 
coded  by  two  coders  to  establish  inter-rater  reliability  in 
assigning these categories to the video set (as a suggested 
practice  in  [18]).  As  our  agreement  in  the  assignments  of 
these categories was high (Krippendorff's alpha nominal = 
0.87), we proceeded to independently categorize each of the 
remaining 249 videos. 
API and Scraped Statistics 
We gathered quantitative statistics to compare videos iden-
tified  as  youth-authored  by  the  Turkers  versus  videos  that 
the  Turkers  did  not  mark  as  youth-authored.  We  used  the 
YouTube API and scraped Vine data to gather information 
about  each  video  and  the  users  who  posted  each  video 
(some users posted multiple videos during the data collec-
tion  phase).  For  these  statistics,  we  excluded  only  videos 
that were deleted by the author before the Turker’s estima-

1430

SESSION: MUSEUMS AND PUBLIC SPACES

YouTube 
(N=131) 

Vine 

 (N=148) 

 

14.3 
2.10 
34.5% 
76.2% 
88.5% 
1.54% 

17.0 
1.67 
17.9% 
92.6% 
79.7% 
18.9% 

Avg. Estimated Age 
Avg. # Youths in Video 
% Adult Collaborations 
% Shows Youth’s Face 
% Youth’s Voice Heard 
% Inappropriate 
Table 4. Age, collaboration, and rule-following characteris-
tics of youth-authored videos on YouTube and Vine, includ-
ing  the  estimated  age  of  the  author,  number  of  youths  ap-
pearing  in  the  video,  percent  of  videos  that  seem  to  have 
been created in collaboration with adults, percent of videos 
where  the  youth’s  face  is  visible  and  voice  is  audible,  and 
percentage of videos containing inappropriate content (cod-
ed as significant violence, cursing, or sexual content). 

 

 

tion of the age of the author. Table 2 summarizes the char-
acteristics  of  the  Vine  videos,  which  shows  that  generally 
youth-authored videos and youth users received as much or 
more  attention  than  non-youth-authored  videos.  Table  3 
summarizes  the  characteristics  of  the  YouTube  videos, 
showing that youth-authored videos on YouTube generally 
received  less  attention  than  other  videos.  Additionally, 
youth  users  on  YouTube  were  less  active  than  non-youth 
users in terms of median videos posted, views of those vid-
eos,  and  subscribers.  An  interesting  characteristic  of  both 
data sets was that the authors removed a significant propor-
tion  of  videos  within  the  first  three  months  of  posting. 
Youth authors seemed to be slightly more likely than adult 
authors to remove posted videos. However, most interesting 
characteristics of videos could not be automatically scraped 
or gathered from the website, so we culled the set to most 
relevant  videos  (see  “Content  Analysis  Process”  section) 
and hand-coded the remaining videos. 
Directed Content Analysis of Youth-Authored Videos 
We coded the filtered and culled youth-authored videos for 
several aspects of their production characteristics (e.g., col-
laboration, number of actors on screen, etc.) and content. 
Collaboration  and  Rule-Following  Characteristics  of  the 
Youth-Authored Videos 
In  our  situating  study,  many  parents  mentioned  specific 
rules  for  their  children  regarding  the  videos  they  create. 
While we did not survey the parents of the children whose 
videos we coded, the survey did give us some insight into 
potential  rules  that  some  parents  introduce  for  their  chil-
dren’s online video. We coded the videos for some of the 
rules mentioned by those parents to see if any proportion of 
the  youth-authored  video  followed  these.  Some  parents 
mentioned  that  children  were  allowed  to  create  remixed 
content or make videos about activities (e.g., video games, 
playing  with  toys)  but  not  have  themselves  appear  in  the 
video.  However,  we  found  that  youth  faces  appeared  in 
76.2%  of  youth-authored  YouTube  videos  and  92.6%  of 
youth-authored Vine videos. For videos where the author’s 
face  did  not  appear,  we  examined  other  videos  posted  on 
the  same  account.  We  saw  only  three  examples  of  an  ac-

CSCW '16, FEBRUARY 27–MARCH2, 2016, SAN FRANCISCO, CA, USA

count that seemed to explicitly follow the “no showing fac-
es” rule: a YouTube account where the child only acted out 
videos with toys and two YouTube game streaming channel 
where no webcam was used. In all other accounts, the au-
thors did reveal their faces in other posted videos, thus the 
omission of the face in the coded video seemed to be more 
a factor of production choice than following a consistent set 
of  rules.  Parents  also  mentioned  having  many  guidelines 
about appropriate dress, language, and content in the vide-
os, a topic we approach later in this section. 
We coded for a number of age and collaboration character-
istics  of  the  posted  videos  (see  Table  4).  We  wanted  to 
know the average age of the video author in these videos, 
estimating it from evidence such as the video itself, the ac-
count  description,  and  other  videos  on  the  account.  We 
found  that  both  children  and  teenagers  of  various  ages 
shared YouTube videos, while Vine was mostly dominated 
by  older  teens.  On  both  sites,  our  observations  included 
children as young as 3 creating videos with an adult’s help, 
up  to  teenagers  judged  to  be  between  19  and  20  (youths 
older than 20 were excluded from the study). Many videos 
were  inherently  collaborative,  with  multiple  young  people 
appearing  in  the  same  video.  On  YouTube,  videos  con-
tained 2.10 children or teenagers on average. Many videos 
also  contained  adults,  with  most  of  these  adults  acting  as 
active  participants  in  the  video  creation  (e.g.,  speaking  on 
or off-camera, participating in the story, hosting the video 
on their account, etc.). We coded the videos that we viewed 
as active collaborations between adult and youths and found 

that  a  little  over  a  third  of  YouTube  videos  fell  into  this 
category. On Vine, the average number of youth in the vid-
eos  is  1.67  which  is  surprisingly  high  given  the  6-second 
video  length  description.  In  many  of  these  videos,  other 
youths featured were younger relatives instead of peers. In 
contrast  to  YouTube,  adults  were  rarely  present  in  these 
videos.  Collaborations  with  adults  were  also  considerably 
less common than on YouTube, representing only 17.9% of 
the  videos.  All  of  these  factors  draw  a  contrast  between 
YouTube as a family space for younger authors versus Vine 
as a playground for older teens.  
Indeed, the lack of following rules on Vine was also clearly 
represented with the significant amount of content that we 
coded as violent, sexual, or obscene. We were fairly moder-
ate in tagging videos with this code, only including videos 
that two coders agreed were significantly offensive. In the 
violence category, this included several examples of vicious 
schoolyard fights, but not any of the more playful tussles or 
threats of violence. In the sexual category, we included sev-
eral examples of frontal and back nudity, sex toys, and ex-
plicit sexual acts described in the video, but excluded simp-
ly using sexual words in non-sexual contexts or dancing in 
a  manner  that  may  be  construed  as  sexual  (e.g.,  “twerk-
ing”). In the obscene category, we included only videos that 
had more than one example of curse words, racial slurs, and 
obscene behaviors. We saw only two YouTube videos that 
had inappropriate content that fell in the “violent, sexual, or 
obscene” category (one depicted a schoolyard fight between 
two  teenage  women,  the  other  video  game  violence  and 

Staged: Girls perform a choreo-
graphed dance.    
https://vine.co/v/M9XPgVzX61u  

 

 
Everyday Things: Boy plays popular 
soccer video game. 
http://www.youtube.com/watch?v=-
EsBPUKWmTQ  

 
Creative Remix: Combination of 
music video and popular vine 
https://vine.co/v/MEn2TEpD0p5  

Selfies & Opinions: Girl com-
plains about her mom. 
https://vine.co/v/hTQEVKqXjHJ  

 

Event Attended: Student section 
participations in football tradition. 
https://vine.co/v/MAgW9a6KuTe 

 

Tutorial: Girl shows customization of 
popular game, Minecraft. 
https://www.youtube.com/watch?v=eOdahoAsgEA  

 

Acted Response: Recorded reac-
tion framing another’s Vine. 
https://vine.co/v/MxJrZF23nOn  

 

 
Funny Things: Demonstration of 
newly created dance moves. 
https://vine.co/v/MvqDUz5z9On  

Figure 3. Traced screenshots of examples of videos for each video category observed in the youth-authored video data set. 

 

1431

cursing). However, roughly 18.9% of videos on Vine vide-
os posted by children and teenagers fell into this category. 
Additionally, we saw many examples of videos that would 
be  considered  homophobic  (friends  mocking  each  other 
about “knowing what ass tastes like”), misogynistic (young 
man expressing his opinion on women as “these bitches”), 
and racially charged (racial slurs, imitating what other races 
are “like”). 
Content of the Youth-Authored Videos 
We used the directed content analysis method to categorize 
the content (see Figure 4) of the youth-authored video into 
each  of  the  seven  categories  identified  by  the  Pew  Online 
Video survey [30], however we also identified two catego-
ries of video that were distinct. We describe each category 
and provide examples (see Figure 3): 
1.  Staged,  Scripted  or  Choreographed  Activity  was  a 
particularly  common  activity  in  youth-authored  video 
with 62% of Vine and 28% of YouTube videos falling 
in  this  category.  A  common  type  of  this  on  both 
YouTube  and  Vine  was  a  performance,  particularly 
singing, rapping, or dancing for the camera. However, 
Vine  videos  were  also  particularly  likely  to  contain 
short  skits  (usually  humorous)  on  a  variety  of  topics. 
Many Vine accounts featured recurring skit topics and 
characters (e.g., a stern mustachioed father as acted by 
his teenage son). 

2.  Videos  of  Doing  Everyday  Things  was  a  common 
category of video, found in 26% of Vine and 44% of 
YouTube  videos.  While  the  original  Pew  survey  only 
included “videos of family and friends doing everyday 
things,” we expanded this definition to include videos 
of self, as we observed that these included largely the 
same content as other “doing everyday things videos.” 
This expansion is consistent with how other Pew cate-
gories  were  defined  (i.e.,  “themselves  or  others”); 
however,  it  is  distinctly  different  from  the  “video 
selfie” category in that it includes everyday activity ra-
ther than simply expressing an opinion at the camera. 
Examples  of  this  included  playing  video  games  and 
spending time with friends after school. In one poign-
ant example, a teen records himself in the everyday ac-
tivity  of  going  to  a  convenience  store,  capturing  and 
commenting  on  the  clerk  of  the  store  “unobtrusively” 
following him to make sure he doesn’t steal anything. 

3.  Videos  of  Themselves  or  Others  Doing  Funny 
Things was a very common category on Vine (41% of 
the videos) but less common in the youth-authored vid-
eos  on  YouTube  (15%).  Humor  seems  to  be  a  huge 
component  of  Vine  videos  and  the  youth  frequently 
shared, acted (see #1 above), or re-enacted (see #9 be-
low). The humor presented was typically in the form of 
action (e.g., funny dance move, falling), joke (e.g., “Is 
your refrigerator running?”), antics of younger children 
(e.g., mishearing song lyrics), or funny skit (e.g., imi-
tating an awkward teacher). 

1432

SESSION: MUSEUMS AND PUBLIC SPACES

4.  Creative Remix of Content or Material includes cre-
atively combining multiple sources of existing content 
(this is different from simply copying existing content 
to an account without modifying it). We observed this 
activity in 11% of Vine and 4% of observed YouTube 
videos. A common type of activity included remixing a 
video  meme  (e.g.,  a  video  of  a  girl  in  a  car  saying 
“broom broom” on Vine) with other memes or artistic 
content (e.g., music video). 

5.  Videos of an Event They Attended includes videos of 
sporting  events,  concerts,  and  other  organized  activi-
ties.  These  formed  6%  of  Vine  videos  and  9%  of 
YouTube  videos  in  our  data  set,  examples  including 
school  sports  events,  large  concerts,  conventions,  and 
parties.  

6.  Video Tutorials or How To Videos aim to educate the 
audience about a specific topic or teach a specific skill. 
14% of the Youth YouTube videos fell into this catego-
ry;  the  examples  included  a  make-up  tutorial  from  a 
teenage girl and a tutorial of a particular Minecraft skill 
from a young boy. There were no videos of this catego-
ry  on  Vine,  most  likely  because  the  6-second  format 
does not lend itself to tutorial-based sharing. 

7.  Videos of Pets or Animals were largely excluded from 
our data set (with only one example Vine video in this 
category). This is likely not a characteristic of author-
ship but rather that many pet or animal videos may not 
make it possible to distinguish the age of the author if 
they do not speak or reveal themselves in the shot. We 
did  see  examples  of  pet/animal  videos  outside  of  the 
data set but on the accounts of identified youth authors. 
The  two  categories  below  did  not  appear  in  the  previous 
work on online video, but represented significant or unique 
aspects of observed youth video authorship: 
8.  Video Selfies & Expressing an Opinion is a common 
category  of  youth-authored  video  with  25%  of 
YouTube and 15% of Vine videos falling in the catego-
ry. In videos of this category, the youth looks directly 
at  the  camera  and  either  expresses  an  affected  action 
(e.g., smooching the camera, making faces) or a specif-
ic opinion (saying, “If you tell me to text you, you need 
to text back, stupid;” expressing a negative opinion of a 
specific  video  game,  etc.).  These  videos  generally 
seemed  fairly  staged  and  had  a  performative,  spoken-
word quality to them. 

9.  Acted  Response  is  a  new  category  of  video  that  we 
identified on both Vine (5%) and YouTube (4%). Un-
like the “creative remix” category, acted responses in-
cluded new content, featuring the author of the video. 
Two categories of acted response were “framing” and 
“re-enacting.” Framing involved including clips of oth-
ers’ content in an acted story. For example, one teenag-
er edited another’s video of children getting in trouble 
into a skit about the perils of babysitting. In many other 
examples, teenagers would include a clip of another’s 
video framed by their own response to that video. The 

CSCW '16, FEBRUARY 27–MARCH2, 2016, SAN FRANCISCO, CA, USA

second  category  of  acted  response  was  re-enacting  a 
popular video. For example, one viral video showed a 
teenager hearing a favorite song, beginning to dance to 
it,  and  then  slipping  and  falling.  Several  other  Vines 
reenacted this video, with the same music, dance, and 
resulting fall but in different contexts (e.g., wet floors, 
tripping  on  a  dishwasher  door,  stepping  on  a  running 
treadmill).  On  YouTube,  this  category  consisted  of 
youths reenacting music videos, movie scenes, or other 
popular videos. 

We must emphasize that many of the videos fell into multi-
ple categories, for example in one video a teenager recorded 
a funny (category 3) skit (category 1) framing as an acted 
response (category 9) to a popular Vine meme. 
Limitations and Cautions 
There  were  several  limitations  to  our  approach.  The  first 
two  limitations  focus  on  identifying  youth  authors  from 
videos and user accounts, which was an ambiguous process. 
First, many videos and accounts do not give any clues as to 
the age or identity of the authors. Those videos received a 
rating of 0 from the Turkers and were not included in the 
analysis,  but  could  have  potentially  been  authored  by 
children or teenagers. One symptom of this problem may be 
the dearth of videos about pets/animals in our sample, since 
those would not have been identified if the author does not 
speak  or  appear  in  the  video  or  provide  any  clues  about 
their age elsewhere on the account. Second, although each 
video  was  rated  by  two  qualified  Turkers,  many  Turkers 
disagreed  on  their  ratings.  We  decided  to  exclude  those 
videos with rater conflict of more than one point from our 
coded collection, and only consider videos with ratings of 3 
or 4 from both Turkers. In practice, this also means that we 
may  have  missed  some  relevant  videos  from  the  set. 
Overall,  we  can  vouch  for  the  high  precision  of  our  final 
data set, but not for its recall.  
There  were  also  two  limitations  to  our  coding.  Several 
findings may be affected by our estimations of authors’ age. 
There  were  several  borderline  age  examples  in  the  Turker 
filtered data set. We removed such videos from the analysis 
when two researchers agreed the author was likely over the 
age of 20 (5% of the videos). However, the estimated ages 
of  our  video  authors  came  from  the  best  guesses  of  the 
researchers  based  on  the  available  data.  Although  we 
cannot  guarantee  complete  accuracy,  we  did  have  high 
inter-rater  agreement  in  these  estimates  and  therefore  fair 
confidence they were reasonable. Finally, 6% videos in our 
sample  came  from  user  accounts  that  may  not  represent  a 
single author. These included curated accounts on specific 
topics  (e.g.,  funny  kid  videos)  and  collection  accounts 
where  no 
identified  (e.g., 
account collecting videos of sport games of a specific high 
school).  We  resolved  this  by  removing  these  videos  from 
analysis, but better handling of collection accounts may add 
new insights in the future. 

individual  contributor  was 

 
Figure 4. Percentage of Vine and YouTube videos in each content 
category identified in the Pew Online Video survey [30], as well as 
two new categories identified in this work (Selfies & Opinions and 
Acted Response). 
 
DISCUSSION 
In our study, we saw examples of children and teenagers as 
active video content creators. Even with conservative filter-
ing (i.e., discarding videos without age evidence, discarding 
videos where raters disagreed on age), youth-authored vid-
eos composed 3% of the YouTube videos and 17% of the 
Vine videos. In this section, we reflect on our content filter-
ing  approach,  discuss  our  findings  in  light  of  previous 
work, and end by considering some implications and oppor-
tunities for design.  
Reflecting on Crowdsourced Content Filtering 
The filtering approach we took in this work worked well at 
identifying a relevant data set for analysis. While this kind 
of filtering may seem obvious in retrospect to crowdsourc-
ing  experts,  it  has  not  been  used  in  previous  studies  and 
presents an interesting alternative to the growing approach 
of  search-based  selection  for  video-based  content  analysis 
[5,19]. In the process of developing the method, we found 
that it was more complex than a standard “categorization” 
task  and  we  describe  the  specifics  of  our  approach  to  ad-
dressing  this  complexity  in  the  section  “Filtering  Youth-
Authored Video.” Others may be able to use a similar ap-
proach to video analysis, as it can also be adapted to sup-
port other situations where a human can easily categorize a 
video  but  a  computer  may  struggle.  For  example,  in  our 
dataset  of  videos,  we  saw  many  racially  charged  discus-
sions. Turkers could help filter videos by African-American 
Viners to help understand the unique perspectives and sto-
ries  of  this  group  on  Vine.  Additionally,  crowd-filtering 
methods can be combined with traditional keyword search 

1433

(e.g.,  “WoW,”  “LoL”)  and 

approaches.  For  example,  somebody  studying  video  game 
experiences could first search for video gamecasts of rele-
vant  games 
then  ask 
crowdworkers to filter based on the specific game behavior 
of interest (e.g., video creator losing the game). However, 
we acknowledge that there are significant opportunities for 
improving this method by considering alternative approach-
es to redundancy and validation. There may also be an op-
portunity  for  crowdsourcing  to  enable  larger  scale  video 
analysis  by  incorporating  “crowd”  stages  at  key  points  in 
the  process.  For  example,  while  developing  categories  of 
content required a “bird’s eye” view of the qualitative data 
to ensure capturing important patterns in the data, the final 
process  of  labeling  videos  with  appropriate  categories  can 
easily  be  adapted  as  a  crowdsourcing  request  to  allow  for 
larger scale analysis.  
YouTube is a Family Space, While Vine is a Playground 
for Teenagers 
Through this work, we saw many differences between the 
youth-authored content on Vine versus YouTube. Some of 
these differences were undoubtedly due to the specifics of 
the  medium.  For  example,  the  6-second  format  of  Vine 
does not lend itself well to video tutorials or how-to videos. 
However,  other  differences  may  be  due  to  the  community 
and practices of each website. We found that the YouTube 
creators were on average younger, more likely to collabo-
rate with adults on the videos, and much less likely to in-
clude inappropriate content. In our situating study, parents 
expressed that they were aware of YouTube and monitored 
their children’s activity on the site. On the other hand, Vine 
authors were mostly mid- to older-teenagers, who were not 
as likely to include adults as collaborators in the videos, and 
were  much  more  likely  to  post  inappropriate,  vulgar,  or 
risky  content.  The  age  difference  between  the  platforms 
may  be  explained  by  the  younger  “recommended”  age  of 
YouTube  creators  (13+)  versus  Vine  creators  (17+) 
(though, we saw creators younger than these recommended 
ages on both sites). While both sites moderate content and 
have  policies  for  limiting  access  to  adult  content  (e.g., 
clicking  to  confirm  age  on  certain  videos),  our  study  has 
revealed that the de facto moderation practices on Vine may 
be looser than those on YouTube.  
Though  it  is  easy  to  discount  inappropriate  content  as  a 
parenting failure, it is also important to remember that teen-
agers “fashion themselves” through their language in con-
texts  like  this  [14],  faceting  and  exploring  their  identities 
through risky content creation [12,27], and developing cop-
ing and resilience skills for later online interactions [37]. It 
is also important to acknowledge the creative behaviors that 
characterized Vine, such as building on each other’s work 
through remixes and acted responses that were reminiscent 
of  playground  play  [13],  including  playful  mimicry  and 
storytelling. Clearly, YouTube and Vine video sharing sites 
each  offer  a  distinct  flavor  of  creative  platform  that  high-
lights differing, yet equally important expression values. 

1434

SESSION: MUSEUMS AND PUBLIC SPACES

Intentionally staged, scripted, or choreographed videos 

Adults  May  Use  Online  Video  as  Archive;  Youth  Use 
Online Video as Stage 
We  cautiously  compared  adult  and  child  video  practices. 
Pew  Internet  Research  conducted  a  large-scale  question-
naire asking adults about the content of their shared online 
videos across platforms [30]. Since their study and ours did 
not  use  the  same  methodology  (self-report  versus  content 
analysis), we do not make direct comparisons between per-
centages, but we do examine the relative popularity of each 
category.  The  Pew  study  found  that  most  users  reported 
sharing  the  following  top  four  types  of  videos  (in  order 
from most to least reported): 
1.  Videos of friends and family doing everyday things 
2.  Videos of themselves or others doing funny things 
3.  Videos of an event they attended 
4.  Videos of pets or animals 
In contrast to this, the top four most common types of vide-
os  found  in  our  youth-authored  data  set  (combining  data 
from both Vine and YouTube), included: 
1. 
2.  Videos of friends and family doing everyday things 
3.  Videos of themselves or others doing funny things 
4.  Video selfies and expressing opinions 
Comparing the Pew data set of adult video authorship [30] 
with our own investigation of youth authorship, it could be 
hypothesized that adults view online video as an archive to 
collect  and  keep  precious  memories  of  everyday  life  with 
their  family,  friends,  and  pets,  humorous  moments,  and 
special  events.  In  contrast,  children  and  teenagers  treat 
online video as a stage. In our data set, we saw them using 
online  platforms  mainly  to  perform  (dancing,  singing, 
skits), tell stories (whether capturing their everyday life or 
staged), and express their opinions and identities in a per-
formative  way  (see  Figure  3).  These  are  preliminary  hy-
potheses  that  stem  from  examining  both  studies;  future 
work may find it fruitful to include a more direct compari-
son of intentions in both adults and youth video posts. 
Staging and sharing of the performative youth self in online 
contexts  highlights  the  way  that  interactions  with  media 
forms shape youth identities in the 21st century, corroborat-
ing  identity  development  processes  of  staging  and  per-
formativity  first  written  about  by  sociologist  Erving 
Goffman  [15,16].  Thought  of  in  this  way,  youth  use  Vine 
and YouTube videos to present social performances starring 
themselves, directed at a digital global stage, in ways that 
often  subvert  traditional  notions  of  dramaturgical  perfor-
mance.  Backstage  and  front  stage  divisions  are  blurred: 
home  spaces  become  public  areas;  hidden  habits  like 
grooming  are  broadcast;  taboo  props  like  toilets  are  made 
acceptable and included as part of the stage; and the messi-
ness  of  video  making  is  reflected  openly  in  finished  com-
modities.  The  techniques,  tropes,  and  language  used  by 
youth  reflect  a  melting  pot  of  media  approaches,  adapted 
and  reshaped  from  genres  of  reality  television,  comedic 

CSCW '16, FEBRUARY 27–MARCH2, 2016, SAN FRANCISCO, CA, USA

parody  news  media  and  popular  online  celebrities.  These 
remixes reflect the currently dominant viral flow processes 
of modern video media [28], embedded in an always con-
nected world, in which media engagement is a tri-fold pro-
cess  that  incorporates  attention,  affinity  and  extension  or 
diffusion of existing content in new ways [1,29,36].   
Implications and Directions for Technology Design 
We  set  out  with  one  goal  being  the  consideration  of  chil-
dren’s  online  safety,  but  it  may  be  important  to  explore 
counterpoints as well, acknowledging that the idea of online 
safety  can  be  taken  to  an  extreme.  For  example,  Google 
recently  released  a  new  application  called  YouTube  Kids, 
which  limits  content  to  popular  children’s  programming 
and  “kid-friendly  content  from  filmmakers,  teachers,  and 
creators.” The official app description boasts that it screens 
out  “videos  that  make  parents  nervous”  and  only  shows 
“videos  that  parents  can  feel  good  about”  [45].  While 
YouTube Kids is targeted at a younger audience than those 
studied  in  this  paper,  it  is  representative  of  common  atti-
tudes towards online safety of minors. While it is certainly 
admirable to protect a vulnerable population, this seems to 
stand in stark contrast to the online youth creative commu-
nities  we  have  observed  in  this  study.  Reducing  children 
and teenagers to content consumers rather than empowering 
them as creators, we may be doing a disservice by quieting 
their voices and taking away their agency. Certainly, there 
was  plenty  in  the  videos  we  observed  that  would  “make 
parents nervous,” but this activity was authentic and mean-
ingful in its own way. We saw youth-authored videos that 
explored complicated ideas like race, gender, sexuality, and 
violence in ways that were both vulgar/offensive, but also 
(and  sometimes  simultaneously)  in  ways  that  were  reflec-
tive and personal. Examples included: teenagers passionate-
ly arguing about race on camera, a video selfie of a young 
women  “telling  off”  men  who  objectify  her,  a  video  of  a 
teenager discussing her sexual orientation and “telling off” 
“haters” in a rap performance, and a black teenager captur-
ing  on-camera  discrimination  against  him.  As  others  have 
pointed out [7,32], sometimes discomfort can be a produc-
tive place to be. 
To consider next steps for design, we reflect on three points 
taken  together:  (1)  parents  worry  about  their  children  pre-
senting themselves online in socially-acceptable ways (e.g., 
previous work [40] and our situating study); (2) youths use 
online spaces like Vine to experiment with their identity in 
sometimes  violent,  sexual,  or  obscene  ways  (one  of  the 
findings of this work); and (3) this type of identity experi-
mentation  has  been  shown  to  be  particularly  important  to 
youths developing resilience in the long run (e.g., previous 
work [37]). Considering these three ideas in concert points 
to  specific  challenges  for  technology  to  support  youth 
online video authorship practices. As an alternative to con-
trolling  what  youth  authors  post  online,  we  can  consider 
technologies  that  empower  the  authors  to  reflect  on  their 
content  and  manage  their  self-presentation.  As  youths  use 
the online playground of video sharing communities to ex-

plore  their  identity,  we  should  design  tools  that  can  help 
this  exploration  be  a  less  permanent  part  of  their  online 
presence. One such idea may be designing an NLP tool that 
crawls an author’s videos identifying ones that may contain 
offensive language so that the author can have the option of 
removing those or making them private as they move into 
adult life. Considering that many of the authors in this study 
posted  dozens  or  hundreds  of  videos,  such  a  tool  would 
considerably  simplify  managing  self-presentation.  Another 
idea may be supporting smarter video deletion. We saw that 
many children and teenagers delete their videos within the 
first three months of posting it (and many may wish to de-
lete some of their videos in the future). Unfortunately, due 
to the high rate of user-copied content sharing online [11], 
deleting one’s own video post may not prevent its contin-
ued  distribution.  A  tool  to  help  the  author  crawl  content 
sites identifying content they own and would like to remove 
could help authors retain control of their content and their 
presentation of self. However, one challenge that arises in 
this scenario is dealing with remixed content or content that 
has  been  modified  with  a  framing  Acted  Response.  There 
are obvious questions as to who owns the new digital arti-
fact that has been created through this process. Besides the 
two  extremes  of  giving  the  original  versus  the  editing  au-
thor  complete  control  of  the  content,  as  automatic  video 
processing technologies improve, we may be able to offer 
better in-between alternatives such as automatically censor-
ing  identifying  content  in  the  original  author’s  portion  of 
the work or converting the original portion to a less identi-
fiable format through a process like automatic cartooning. 
CONCLUSION 
In  this  work  we  examined  the  content  that  children  and 
teenagers author and share on public video platforms (spe-
cifically,  YouTube  and  Vine).  In  order  to  identify  youth-
authored  videos,  we  proposed  and  piloted  a  new  filtering 
method that leverages crowdworkers to filter relevant con-
tent  for  additional  analysis.  We  coded  filtered  videos  by 
hand to identify the type of content that each video shared. 
We found that youth videos have a content type not previ-
ously identified in studies of online video content sharing: 
“Selfies  &  Opinions.”  We  also  found  an  unusual  style  of 
creatively  building  on  the  work  of  others—a  content  type 
we titled “Acted Response.” We identify important differ-
ences  in  youth  video  authorship  on  YouTube  and  Vine, 
particularly  that  Vine  videos  included  significantly  more 
violent,  sexual,  and  obscene  content.  Finally,  we  build  on 
previous  work  to  tentatively  contribute  the  contrast  that 
adults  may  use  online  video  as  an  archive,  while  children 
and teenagers use online video as a stage. Our findings re-
veal  unique  aspects  of  and  opportunities  for  supporting 
youth video authorship. 
ACKNOWLEDGMENTS 
We want to thank to Kori Inkpen, Leah Findlater, and Alex 
Quinn for their early guidance of this research endeavor. A 
portion  of  this  work  was  funded  by  a  SOBACO  faculty 
grant. 

1435

REFERENCES 
1.  S. Alhabash and A. R. McAlister. 2014. Redefining vi-
rality in less broad strokes: Predicting viral behavioral 
intentions from motivations and uses of Facebook and 
Twitter. New Media & Society.  

2.  Amazon Web Services, Inc. 2014. Mechanical Turk: 

Requester UI Guide (API Version 2014-08-15). 

3.  Amazon Web Services, Inc. 2014. Amazon Mechanical 
Turk: Command Line Reference (API Version 2014-08-
15). 

4.  Tawfiq Ammari, Priya Kumar, Cliff Lampe, and Sarita 
Schoenebeck. 2015. Managing Children’s Online Iden-
tities: How Parents Decide What to Disclose About 
Their Children Online. Proc. of CHI, 1895–1904. 

5.  Lisa Anthony, YooJin Kim, and Leah Findlater. 2013. 
Analyzing User-generated Youtube Videos to Under-
stand Touchscreen Use by People with Motor Impair-
ments. Proc. of CHI, 1223–1232. 

6.  Marlene Asselin, Teresa Dobson, Eric M. Meyers, Cris-

tina Teixiera, and Linda Ham. 2011. Learning from 
YouTube: An Analysis of Information Literacy in User 
Discourse. Proc. of  iConference, 640–642. 

7.  Steve Benford, Chris Greenhalgh, Gabriella Giannachi, 
Brendan Walker, Joe Marshall, and Tom Rodden. 2012. 
Uncomfortable Interactions. Proceedings of the SIGCHI 
Conference on Human Factors in Computing Systems, 
ACM, 2005–2014.  

8.  Joan-Isaac Biel and Daniel Gatica-Perez. 2011. 

VlogSense: Conversational Behavior and Social Atten-
tion in YouTube. ACM Trans. Multimedia Comput. 
Commun. Appl. 7S, 1, 33:1–33:21.  

9.  Tatiana Buhler, Carman Neustaedter, and Serena Hill-
man. 2013. How and Why Teenagers Use Video Chat. 
Proceedings of the 2013 Conference on Computer Sup-
ported Cooperative Work, ACM, 759–768.  

10. Nicholas Diakopoulos, Kurt Luther, Yevgeniy (Eugene) 
Medynskiy, and Irfan Essa. 2007. The Evolution of Au-
thorship in a Remix Society. Proceedings of the Eight-
eenth Conference on Hypertext and Hypermedia, ACM, 
133–136. 

11. Yuan Ding, Yuan Du, Yingkai Hu, et al. 2011. Broad-

cast Yourself: Understanding YouTube Uploaders. Pro-
ceedings of the 2011 ACM SIGCOMM Conference on 
Internet Measurement Conference, ACM, 361–370.  
12. Shelly D. Farnham and Elizabeth F. Churchill. 2011. 
Faceted Identity, Faceted Lives: Social and Technical 
Issues with Being Yourself Online. Proceedings of the 
ACM 2011 Conference on Computer Supported Coop-
erative Work, ACM, 359–368.  

13. Joe L. Frost. 2009. A History of Children’s Play and 
Play Environments: Toward a Contemporary Child-
Saving Movement. Routledge. 

1436

SESSION: MUSEUMS AND PUBLIC SPACES

14. James Paul Gee, Anna-Ruth Allen, and Katherine Clin-

ton. 2001. Language, Class, and Identity: Teenagers 
Fashioning Themselves Through Language. Linguistics 
and Education 12, 2, 175–194.  

15. Erving Goffman. 1982. Interaction Ritual - Essays on 

Face-to-Face Behavior. Pantheon. 

16. Erving Goffman. 1990. The presentation of self in eve-

ryday life. Anchor Books, New York, NY. 

17. Rebecca E. Grinter and Leysia Palen. 2002. Instant Mes-
saging in Teen Life. Proceedings of the 2002 ACM Con-
ference on Computer Supported Cooperative Work, 
ACM, 21–30. 

18. Kevin A. Hallgren. 2012. Computing Inter-Rater Relia-
bility for Observational Data: An Overview and Tutori-
al. Tutorials in quantitative methods for psychology 8, 
1, 23–34. 

19. Juan Pablo Hourcade, Sarah L. Mascher, David Wu, and 
Luiza Pantoja. 2015. Look, My Baby Is Using an iPad! 
An Analysis of YouTube Videos of Infants and Tod-
dlers Using Tablets. Proc. of CHI, ACM, 1915–1924. 
20. Hsiu-Fang Hsieh and Sarah E. Shannon. 2005. Three 

Approaches to Qualitative Content Analysis. Qualitative 
Health Research 15, 9, 1277–1288.  

21. Jin Yea Jang, Kyungsik Han, Patrick C. Shih, and 

Dongwon Lee. 2015. Generation Like: Comparative 
Characteristics in Instagram. Proc. of CHI, ACM, 
4039–4042. 

22. Haiyan Jia, Pamela J. Wisniewski, Heng Xu, Mary Beth 

Rosson, and John M. Carroll. 2015. Risk-taking As a 
Learning Process for Shaping Teen’s Online Infor-
mation Privacy Behaviors. Proceedings of the 18th 
ACM Conference on Computer Supported Cooperative 
Work & Social Computing, ACM, 583–599.  

23. Oskar Juhlin, Goranka Zoric, Arvid Engström, and Erika 
Reponen. 2014. Video Interaction: A Research Agenda. 
Personal Ubiquitous Comput. 18, 3, 685–692.  

24. Amanda Lenhart, Maeve Duggan, Renee Stepler, Lee 
Rainie, and Kim Parker. Teens, Social Media & Tech-
nology Overview 2015. Retrieved May 12, 2015 from 
http://www.pewinternet.org/files/2015/04/PI_Teensand
Tech_Update2015_0409151.pdf 

25. Greg Little, Lydia B. Chilton, Max Goldman, and Rob-
ert C. Miller. 2010. TurKit: Human Computation Algo-
rithms on Mechanical Turk. Proceedings of the 23Nd 
Annual ACM Symposium on User Interface Software 
and Technology, ACM, 57–66.  

26. Leslie S. Liu, Jina Huh, Tina Neogi, Kori Inkpen, and 
Wanda Pratt. 2013. Health Vlogger-viewer Interaction 
in Chronic Illness Management. Proc. of CHI, 49–58.  
27. Sonia Livingstone. 2008. Taking risky opportunities in 
youthful content creation: teenagers’ use of social net-
working sites for intimacy, privacy and self-expression. 
New Media & Society 10, 3, 393–411.  

41. Lei Zhang, Feng Wang, and Jiangchuan Liu. 2014. Un-

derstand Instant Video Clip Sharing on Mobile Plat-
forms: Twitter’s Vine As a Case Study. Proc. of 
NOSSDAV, 85:85–85:90. 

42. Transcript – Generation Like. FRONTLINE. Retrieved 

May 20, 2015 from 
http://www.pbs.org/wgbh/pages/frontline/media/generat
ion-like/transcript-57/ 

43. Meet the stars of YouTube’s teen empire. The Daily 

Dot. Retrieved May 20, 2015 from 
http://www.dailydot.com/entertainment/awesomenesstv-
youtube-stars-ingrid-nilson/ 

44. Vine Stars Are The New Boy Bands. ReadWrite. Re-

trieved May 22, 2015 from 
http://readwrite.com/2014/09/02/vine-stars-boy-band-
youtube-teens-digitour 

45. YouTube Kids. App Store. Retrieved May 22, 2015 from 

https://itunes.apple.com/us/app/youtube-
kids/id936971630?mt=8 
 

 

CSCW '16, FEBRUARY 27–MARCH2, 2016, SAN FRANCISCO, CA, USA

28. Karine Nahon and Jeff Hemsley. 2013. Going Viral. 

Polity, Malden, MA. 

29. Robert Payne. 2012. Virality 2.0. Cultural Studies 27, 4, 
540–560. http://doi.org/10.1080/09502386.2012.707219 
30. Kristen Purcell. Online Video 2013. Pew Research Cen-
ter’s Internet & American Life Project. Retrieved Octo-
ber 7, 2014 from 
http://www.pewinternet.org/2013/10/10/online-video-
2013/ 

31. Alexander J. Quinn and Benjamin B. Bederson. 2011. 

Human Computation: A Survey and Taxonomy of a 
Growing Field. Proceedings of the SIGCHI Conference 
on Human Factors in Computing Systems, ACM, 1403–
1412.  

32. Kathryn E. Ringland, Christine T. Wolf, Lynn Dom-

browski, and Gillian R. Hayes. 2015. Making “Safe”: 
Community-Centered Practices in a Virtual World Ded-
icated to Children with Autism. Proceedings of the 18th 
ACM Conference on Computer Supported Cooperative 
Work & Social Computing, ACM, 1788–1800.  

33. Dana Rotman, Jennifer Golbeck, and Jennifer Preece. 
2009. The Community is Where the Rapport is – on 
Sense and Structure in the Youtube Community. Pro-
ceedings of the Fourth International Conference on 
Communities and Technologies, ACM, 41–50.  

34. Sergio Sayago, Paula Forbes, and Josep Blat. 2012. Old-

er People’s Social Sharing Practices in YouTube 
Through an Ethnographical Lens. Proceedings of the 
26th Annual BCS Interaction Specialist Group Confer-
ence on People and Computers, British Computer Soci-
ety, 185–194.  

35. Emma Sorbring and Linda Lundin. 2012. Mothers’ and 
fathers’ insights into teenagers’ use of the internet. New 
Media & Society 14, 7, 1181–1197.  

36. Catherine Tucker. 2011. Virality, Network Effects and 
Advertising. MIT, Cambridge, MA. Retrieved July 29, 
2015 from http://archive.nyu.edu/handle/2451/31400 
37. Pamela Wisniewski, Haiyan Jia, Na Wang, et al. 2015. 

Resilience Mitigates the Negative Effects of Adolescent 
Internet Addiction and Online Risk Exposure. Proceed-
ings of the 33rd Annual ACM Conference on Human 
Factors in Computing Systems, ACM, 4029–4038.  

38. Pamela Wisniewski, Haiyan Jia, Heng Xu, Mary Beth 
Rosson, and John M. Carroll. 2015. “Preventative” vs. 
“Reactive”: How Parental Mediation Influences Teens’ 
Social Media Privacy Behaviors. Proc. of CSCW, 302–
316. 

39. Pamela J. Wisniewski, Heng Xu, Mary Beth Rosson, 
and John M. Carroll. 2014. Adolescent Online Safety: 
The “Moral” of the Story. Proc. of CSCW, ACM, 1258–
1271. 

40. Sarita Yardi and Amy Bruckman. 2011. Social and 

Technical Challenges in Parenting Teens ’ Social Media 
Use. Proc. of CHI, 3237–3246. 

1437

