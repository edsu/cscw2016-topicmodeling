CSCW '16, FEBRUARY 27–MARCH2, 2016, SAN FRANCISCO, CA, USA

uncovering tensions in personal data management 

Data Narratives: 

Janet Vertesi1, Jofish Kaye2, Samantha N. Jarosewski1, Vera D. Khovanskaya3, Jenna Song4

1Princeton University 
Sociology Department 
Princeton, NJ, USA 

jvertesi | jarosz at princeton.edu 

2Yahoo 

HCI Research Group 
Sunnyvale, CA, USA 
jofish at yahoo-inc.com 

3Cornell University 
Information Science 
Ithaca, NY, USA 
vdk9 at cornell.edu  

4Columbia University 

Graduate School of Business 

New York, NY, USA 

YSong20 at gsb.columbia.edu 

of 

changing 

background 

ABSTRACT 
We present an interview study of 34 participants in the US 
and Korea who described how they manage their personal 
data, from work files to family photos. Through their “data 
narratives” – accounts of their data management practices, 
including  device  usage  patterns  and  negotiations  with 
system and brand ecosystems – we explore how individuals 
negotiate  a  complex,  multi-service,  and  morally-charged 
sociotechnical  landscape,  balancing  demands  to  share  and 
to  safeguard  their  data  in  appropriate  ways  against  a 
shifting 
technologies, 
relationships,  individuals,  and  corporations.  We  describe 
the guiding framework that people use to make decisions as 
a  “moral  economy”  of  data  management,  contributing  to 
our understanding of context-specific system choices. 
Author Keywords 
Data management; privacy; data sharing; data narratives. 
ACM Classification Keywords 
H.5.m. Miscellaneous  
INTRODUCTION 
Sitting at a Starbucks in Manhattan, Dave, a personal chef 
in  his  forties,  describes  how  he  keeps  his  personal  data. 
“Everything  in  my  house  is  Apple…  I  want  to  be 
comfortable... I don’t need an external hard drive to save a 
motherlode  of  information...  It  stores  it,  all  my  Apple,  my 
iTunes.” He then whipped out his iPhone to impress us with 
photos of his recent trip to Cuba -- which he took with his 
Canon camera, later transferring the best ones to his phone 
to show off to his friends. He then talked us through his use 
of  Yahoo!  email  to  file  recipes  for  his  clients,  his  AOL 
calendar  which  he  used  for  reminders,  and  his  use  of 
Google  translator  to  speak  Spanish  in  Cuba.    Despite  his 
professed  “comfort”  with  one  set  of  products,  then,  Dave, 
like  many  of  us,  coordinates  his  personal  data  –  photos, 
recipes,  emails,  contacts  –  across  multiple  devices  and 
Permission to make digital or hard copies of all or part of this work for 
personal or classroom use is granted without fee provided that copies are 
not made or distributed for profit or commercial advantage and that copies 
bear  this  notice  and  the  full  citation  on  the  first  page.  Copyrights  for 
components  of  this  work  owned  by  others  than  the  author(s)  must  be 
honored.  Abstracting  with  credit  is  permitted.  To  copy  otherwise,  or 
republish,  to  post  on  servers  or  to  redistribute  to  lists,  requires  prior 
specific  permission 
from 
permissions@acm.org. 
CSCW '16, February 27-March 02, 2016, San Francisco, CA, USA  
Copyright  is  held  by  the  owner/author(s).  Publication  rights  licensed  to 
ACM.  
ACM 978-1-4503-3592-8/16/02…$15.00   
DOI: http://dx.doi.org/10.1145/2818048.2820017 

fee.  Request  permissions 

and/or 

a 

services.  He  also  described  clear  and  poignant  ways  of 
using  his  devices  and  choosing  data  management  services 
as  key 
to  managing  his  relationships  with  different 
products,  corporate  actors,  and  people,  each  of  whom  can 
be unpredictable or inconsistent in their actions. 
Authors at CSCW and beyond have examined data sharing, 
privacy,  or  device  and  information  management  in  many 
social contexts. But do these context-specific practices and 
tensions  translate  to  other  domains,  and  what  can  be 
discerned from a wider view? In this paper, we investigate 
everyday  attitudes  and  practices  of  personal  data 
management  writ  large  under  the  open  question,  how  do 
people  manage  their  personal  data?  We  interviewed  33 
individuals in three cities in the US and in Korea to inquire 
into  their  “data  narratives”:  interviewees’  descriptions,  in 
their  own  words,  of  their  data,  data  management  services, 
device ecosystems, and sharing networks. With a wide net 
and  an  eye  to  how  individuals  themselves  describe  their 
tools,  their  practices,  and  their  data,  we  wondered  what 
would  emerge  if  we  asked  individuals  across  a  variety  of 
contexts  to  describe  how  they  think  about  and  practice 
personal data management in their daily lives. 
What  emerged  in  our  interviewees’  data  narratives  was  a 
complex  and  heterogeneous  landscape  of  personal  data 
management  in  which  individuals  described  accessing, 
sharing, and protecting everything from intimate photos and 
videos  to  music  and  work  documents  on  devices  from 
computers to tablets and cell phones. While their methods 
and  choices  were  idiosyncratic,  all  of  our  interviewees 
articulated common points of tension: between sharing and 
safeguarding data in appropriate ways, while negotiating a 
web of relationships with friends, family, and corporations. 
From a system-wide view, these practices were not distinct 
but  interwoven  in  their  narratives  as  they  described  their 
data,  devices,  and  choices  holistically.  We  were  also 
surprised  by  the  strong  moral  undertone  to  the  ways  in 
which people understood and experienced the management 
of their personal data. In their data narratives the onus was 
firmly  on  the  individual  to  protect  and  share  data  in 
appropriate  ways,  against  a  background  of  shifting 
technologies,  personal  relationships,  and  corporate  actors. 
We describe this overarching frame as the moral economy 
of  data  management,  which  we  argue  motivates  both  the 
choices  of  devices  and  services,  and  how  and  with  whom 
people share and safeguard data. 

478

SESSION: MUSEUMS AND PUBLIC SPACES

Prior Work 
Prior studies of data management at CSCW explore various 
aspects  of  data  practices  in  distinct  contexts,  such  as 
scientific  collaborations  [17,40,41,46]  to  parenting  [19]. 
But scientists and mothers are not the only ones drowning 
in  a  data  deluge;  many  individuals  and  their  families  also 
struggle to manage a multitude of devices and services, files 
and  formats  produced  by  smartphones,  tablets,  emails  and 
digital cameras. Thus scholars have also examined various 
distinct  elements  of  data  management,  such  as  how  users 
manage  their  devices  [5]  or  understand  their  storage 
systems [22,28]; the values that underlie their choices [16]; 
the material practices of data work [14,28]; and how people 
“steward” their data traces for the future [3,11,19,28]. 
A comparable line of work at CSCW and related venues has 
demonstrated  how  sharing  data  in  particular  is  part  of 
identity  management.  From  music  files  to  social  media 
comments [44,45], data is implicated in the maintenance of 
social  ties  [2,32]  or  producing  or  saving  “face”  in  social 
contexts [15, 22,24,43]. With this interactional sensibility to 
data work in mind,  recent data privacy studies have argued 
for an equally contextual [27] and relationally-accountable 
[20,39]  notion  of  information  management:  one  in  which 
sharing  and  privacy  strategies  are  continually  negotiated 
and  situated  in  social  relationships  [7,29].  For  instance, 
under Communication Privacy Management Theory (CPM) 
“privacy”  is  centered  in  interactions,  such  that  challenges 
arise in negotiating the complex boundaries of privacy and 
openness  in  relationships  [29].  Others  argue  for  a  concept 
of  “networked  privacy,”  which  considers  the  extent  to 
which  friends,  colleagues  or  family  impact  individuals’ 
online  practices  and  raises  a  critique  of  the  neo-liberal 
selfhood assumed by data management systems [24,29]. 
We are committed to these interactional, contextual studies 
of data management and were pleased to see confirmation 
of  prior  findings  (such  as  the  challenges  of  stewardship, 
sharing,  or  networked  social  relations)  visible  across  a 
multitude of system contexts, as we will discuss. However, 
many of the above cases focus on singular systems such as 
iTunes,  Google  Docs,  Twitter,  or  location  sharing,  or  to 
particular  contexts  such  as  the  workplace  or  the  family. 
This leads Barkhuus to claim that their “findings are often 
locked  into  the  context  of  the  study”  [1]  and  unable  to 
transcend the service at hand. Just as asking questions at the 
ecosystem  level  reveals  new  aspects  of  data  management 
[5,11,12,14,31],  we  hoped  that  exploring  privacy  settings, 
sharing activities and device management as interconnected 
practices united under a common narrative might illuminate 
new  aspects  of  on-the-ground  data  management.  Thus  the 
elements  of  data  management  we  identified  from  this 
perspective  contribute  to  CSCW  theories  of  contextually-
sensitive,  interactional  and  networked  negotiations  of  data 
management  by  placing  these  practices  into  a  wider 
framework: that of the moral economy of data management. 

What is a moral economy? 
Moral  economies  are  produced  by  a  set  of practices  and 
activities that  are  laden  with  affect,  cultural  expectation, 
and responsibility [6,18,25]. They combine what people do 
(practices) with what they say they do and their reasons for 
doing it (narratives); they also combine material resources 
(like servers or cloud systems) with immaterial ones (users’ 
feelings  about  these  resources).  Yet  as  historian  Lorraine 
Daston  describes  the  “moral  economy  of  science,”  moral 
economies  account  not  only  for  local  ways  of  doing 
resource  management:  they  describe  the  locally-accepted 
combination of instruments and practices that are believed 
to produce both good science and good scientists [6]. Thus 
moral  economies  go  beyond  discourse  to  shape  both 
practices and, reflexively, people at the same time.1  
We 
therefore  define  “the  moral  economy  of  data 
management”  as  a  locally-adjudicated  way  of  combining 
devices, services, and social ties so as to personally embody 
a good and appropriate relationship to personal data. That 
is,  as  our  respondents  articulated  a  right  way  to  manage, 
share,  and  use  their  data  in  a  reflexive  performance  of 
identity, this was always with the curation of relationships 
in  mind  but  often  without  an  “audience”  beyond  him-  or 
herself.  Instead,  their  description  of  “the  right  way”  to 
manage their data, devices and services consistent with the 
relational  context  at  hand  established  them  as  responsible 
citizens,  parents,  or  professionals.  Thus  we  argue  that  the 
strong  normative  dimension  of  our  interviewees’  data 
narratives,  combined  with 
implications  for  how  our 
respondents  understand  themselves  as  family  members, 
friends, consumers and citizens, begs more than an analysis 
of self-presentation. 
In the next section we describe our interviews and methods. 
We  then  describe  commonalities  in  the  data  narratives  we 
heard,  and  discuss  the  various  relationships  managed 
through  these  practices:  with  corporations,  with  their 
professional  and  personal  networks.  We  unpack 
the 
considerations  our  informants  took  into  account  in  their 
                                                             
1 While we foreground Daston’s framework, its fit became 
clear only after coding and discussing commonalities across 
the  33  interviews.  Note  that  “moral  economies”  have 
entered  HCI  before,  in  studies  of  domestic  spaces  that 
argued households should be “conceived as a transactional 
system  of  economic  and  social  relations”   [35].  This  lent 
rigor and purposefulness to observed practices in the home, 
associating the comings and goings of different objects and 
people  with  a  shared  social  order.  Both  definitions  are 
based on historian E.P. Thompson’s “moral economies”: a 
lay  view  of  economic  systems  based  not  on  market 
principles  like  supply  and  demand  or  profit  maximization 
but  on  social  norms  and  obligations  like  fairness  and 
consistency  [38].  We  retain  Daston’s  definition  as  she 
focuses  on  the  reflexive  nature  of  the  moral  economy:  the 
mutual shaping of practices and people.  

479

CSCW '16, FEBRUARY 27–MARCH2, 2016, SAN FRANCISCO, CA, USA

their data  narratives:  users’  accounts  of 

choices  of  tools  and  practices,  and  the  fears  they  guard 
against.  We  conclude  by  fleshing  out  the  notion  of  the 
moral  economy  under  which  we  saw  our  informants 
structure 
their  complex  and  situated  decisions,  with 
implications for studies of privacy and data management.   
METHODS 
Our study team of five researchers conducted interviews in 
the  Northeast  Corridor  and  the  Bay  Area,  USA  and  in 
Seoul,  South  Korea.  We  recruited  interviewees  through 
postings on Craigslist, Twitter and similar forums. Several 
participants in the New York area were recruited in public 
spaces. We chose these three cities because they were sites 
where individuals were likely to experience high levels of 
connectivity  and  personal  mobile  computing,  albeit  with 
different platforms and providers, and a range of expertise. 
We  selected  at  least  ten  participants  at  each  location  for 
interviews,  aiming  for  diversity  rather  than  statistical 
representation in age, gender, and technical expertise from 
“lay  users”  to  “lead  users”  (Table  1).  We  thus  aimed  for 
generative, not statistically representative, findings [see 9].  
We  did  not  observe  individuals  interacting  with  their 
systems over time. Instead, we were interested in what we 
called 
their 
systems, their rationales for their choices, and the “just so” 
stories of how their systems came to be. We recognize that 
accounts are often in tension with practices, so we did not 
assume that accounts and practices aligned. Instead, we put 
the  gap  between  them  to  use  in  our  interviews  to  reveal 
some of the fears that participants had about how and what 
they kept, where they kept it, and why. We wanted to know: 
what stories do users associate with their data, and with the 
everyday  access  and  use  of  their  data  in  situ  (i.e.  not  for 
future  use  as  in  [3,28])?  What  do  they  think  of  as  “their 
data”: their email, fantasy football team, IM client, or stock 
portfolio,  for  example?  [c.f.  14]  Which  tools  and  systems 
do they use on a daily basis to manage their data, and why? 
What  folk  wisdom  circulates  about  best  practices  online 
that  influence  user  behavior,  caution,  or  embrace  of  a 
platform?  How  do  people  treat  their  “secret”  or  most 
personal data compared to other kinds of information? And 
how do they rationalize their use of one data management 
system over another? 
Asking someone how and where they keep “their data” can 
easily  lead  to  hand-waving  descriptions  or  an  incomplete 
picture  of  their  data  ecology.  To  facilitate  our  interviews, 
draw a wider net and yet inspire deeper and more thorough 
conversations, we began with the prompt: “draw a map of 
your  data”  [20,31,42].  This  mapping  exercise  was  not 
intended  to  produce  judgments  of  expertise  or  a  clear 
picture of their network of services. Instead, it helped us to 
elicit grounded comments about individuals’ personal data 
practices, to examine how they conceptualize their personal 
data  space,  and  to  produce  generative  (not  generalizable) 
findings  [as  in  9].  As  people  filled  in  their  maps  over  the 
course of the interview on the provided sheets of paper with 

pens and markers, they remembered new stories, discovered 
previously forgotten elements of their systems, and visually 
articulated the relationships and functions of their devices, 
systems, and data. As such the maps played a structural role 
in the interview process, but as tools to think with, we did 
not check them for completeness or accuracy.  
Instead  of  defining  ‘data’  up  front,  we  asked  our 
interviewees  to  tell  us  about  what  they  thought  was  their 
personal data. Interviewees would typically start with a data 
source  or  a  device  in  their  ecosystem,  listing  the  data 
management  services  associated  with  that  data  and  with 
whom or with what that data was shared. They would then 
illustrate  what  they  considered  to  be  data  on  their  maps, 
indicating  how  it  moved,  where  it  was  stored,  and  how  it 
was  accessed.  When  they  reached  a  dead  end  we  might 
prompt with another data-oriented question such as, “What 
about your music?” or “Tell us how you keep your photos,” 
or, “Do you have a tablet?” These prompts led them to fill 
in  more  and  more  of  their  data  maps,  telling  rich  stories 
while they drew. We include a sample of these maps below. 
In our participants’ accounts, then, personal “data” included 
media  files,  photographs,  personal  memos,  contact  lists, 
financial  information,  work  documents,  code,  and  faxed 
documents. While people were conscious of other kinds of 
personal  data  online  such  as  credit  card  information  and 
GPS traces, the majority of participants we spoke to did not 
actively curate this aspect of their data. Even as we focused 
in  on  their  photographs  or  documents  as  the  data  in  their 
home 
services  were  highly 
conspicuous in their accounts. These were the places where 
they kept their data and the platforms for data transfer that 
they  negotiated  or  troubleshot  on  the  move.  Participants 
also  described  how  they  specifically  chose  the  material 
elements  of 
their  data  ecosystem  with  data-based 
interactions very much in mind. 
All but 4 interviews ranged in length from 45 minutes to 2 
hours.  The  interviews  were  transcribed,  and  then  open 
coded  on saturateapp.com by  at  least  two  study  personnel 
members – one senior researcher and one graduate student 
per  transcript  --  to  produce  inter-coder  reliability  and  to 
identify  analytical  opportunities.    The  software  added  our 
codes to a master list shared across the team, and there was 
considerable  overlap  in  coder’s  identifications  of  passages 
of  interest.  The  codes  included  open  coding,  coding  for 
themes  of 
interest,  and  elevating  participants’  own 
nomenclature  to  the  level  of  global  code  as  analytical 
opportunity  (i.e.  “the  right  way”)  [10].  The  interviewers 
also completed and discussed their own personal data maps 
in  the  course  of  the  analysis  to  further  ground  our  own 
perspective  on  the  data  we  gathered.  In  writing  up  our 
findings,  we  chose  quotes  that  are  illustrative  of  broader 
trends,  if  specific  to  particular  individuals.  To  avoid  the 
reader’s  own  sense  of  drowning  in  data,  we  focus  on  a 
recurring  cast  of  characters  to  elucidate  our  broader 
findings. A complete list of interviewees is in Table 1. 

systems,  devices  and 

480

SESSION: MUSEUMS AND PUBLIC SPACES

Four  of  our  interviews  in  Korea  were  subject  to  an 
important  distinction.  When  speaking  with  these  older 
participants, our bilingual Korean interviewer had difficulty 
getting them to speak at length, resulting in interviews less 
than half an hour long. This was not an issue in any of our 
American  interviews,  or  the  other  Korean  interviews; 
however,  lack  of  familiarity  with  the  research  interview 
concept and interactional codes about how to address those 
with seniority impeded our ability to produce a completely 
comparable dataset. Despite these difficulties, we chose to 
include  this  empircal  data  in  our  analysis  because  it 
provided a valuable (if partial) perspective from a different 
demographic.  Combined  with  our  reticence  to  essentialize 
cultural practices, this led us to eschew pronouncements on 
“Korean  versus  American  data  practices.”  Instead  we 
remained attuned to common tensions across sites, even if 
addressed  differently,  and  checked  our  own  assumptions 
about what a “normal” infrastructural environment or data 
ecosystem should be [34,36]. 
THE DATA NARRATIVES 
Our  interviewees’  systems  were  highly  heterogeneous  yet 
had  many  similarities.  They  all  used  desktop  and  laptop 
computers,  mobile  devices  such  as  phones  or  tablets,  and 
mixed  and  matched  these  with  a  variety  of  peripheral 
devices  from  wireless  speakers  to  Fitbits,  internet-enabled 
games 
and 
subscriptions.  For  example,  Kyung-mi,  a  fifty-year  old 
Korean housewife, curated her data across no less than nine 
different devices including several computers, two tablets, a 
phablet, and two phones, all from different companies. She 
also spoke confidently and at great length about the relative 
advantages of Apple versus Android, Google Drive versus 
NDrive or Dropbox, even chastising our interviewer when 
it appeared that she did not know the relative value of each 
system with respect to data privacy and management.  
Kyung-mi had a very strong data narrative about what each 
device or service was for: i.e. “things I have to access a lot 
I make a folder in Dropbox and store there, and NDrive is 
for backup and autosyncs.” Her narrative about what each 
was  good  for  was  equally  strong:  “Some  things  are 
optimized  for  Apple  when  you  use  apps.  Some  things  are 

television  boxes 

to  digital 

consoles 

optimized for Android… now that I use an Android phone 
the connectivity and syncing between Android devices is so 
convenient. But still Apple still has merits and I bought that 
[iPad]  with  retina  display,  good  resolution  so  I  still  use 
Apple.”  Overall,  as  she  put  it,  “Syncing  between  phones, 
tablets,  and  PCs  is  the  norm  now,  so  the  matter  of  [a 
system] being chosen by people or not depends on how this 
kind  of  ecosystem  is  convenient  to  sync  and  whether  you 
can  protect  your  data  when  there’s  a  problem.  If  you’re 
good at these things, you’ll succeed.” We will return to this 
notion of “success” later in the paper. 
In contrast, Dave, the personal chef in New York City, had 
the  closest  to  a  single-company  ecosystem  we  found.    He 
explained  to  us  that  using  all  Apple  products  in  his  home 
helps  him  to  be  “comfortable.”  Still  he  did  not  use  all 
available  features  of  the  Apple  system,  syncing  when  he 
came  home  to  his  personal  wifi  network  instead  of  using 
wireless data transfer, and moving photos from his Canon 
camera by hand over to his Apple devices. He used “Yahoo 
Files” (writing draft emails and storing them in folders) to 
keep  track  of  his  clients’  favorite  recipes,  AOL  for  his 
professional  calendar,  and  Google  translate  while  on 
vacation.  Although  his  devices  and  services  differed  from 
Kyung-mi’s,  Dave  had  an  equally  clear  narrative  for  the 
devices  and  services  he  chose:  in  his  case  managing  his 
relationships to his friends, family, and employers. 
When we asked where our participants stored their data, the 
majority  of  them  used  cloud  services,  such  as  Dropbox, 
Box,  Google  Drive,  NDrive,  and  iCloud.  Some  were 
enrolled automatically into cloud syncing by their devices, 
expressing either anxiety or complacency about this state of 
affairs.  (One  professional  in  his  mid-20’s,  exclaimed  “I’m 
in the cloud while I don’t know it? Oh my God!") To protect 
privacy  even  more  thoroughly,  physical  systems  remained 
conspicuous,  especially  in  Korea  where  many  of  our 
participants  said 
they  avoided  using  cloud  services 
altogether  and  preferred  USB  sticks  and  external  hard 
drives  for  physical  backups.  At  the  same  time,  another 
interviewee in her late-20’s shrugged that she didn’t know 
how to delete auto-synced files so “I left it that way.”  

Table 1: Participant aliases, ages, and occupations. Columns left-to-right are Bay Area, Northeast Corridor, and Seoul. 

Name 

Name 
Betsy (25F) 
Cathy (58F) 
Harry (28M)  magician 
Ivory (32F) 
Laura (38F) 
Ninja (34F) 
Quinn (50F) 
Sam (45M) 
Tania (63F) 
Terry (48F)  mom 
Lisa (23F) 
 

Occupation 
student/service rep  Ned (30M) 
Stan (25M) 
actor (medical) 
Thomas (30M) 
Orlando (41M) 
Dave (40M) 
Daniel (30+M) 
Boris (42M) 
Kevin (36M) 
Francis (24F) 
Liz (27F) 
Ulysses (40+M) 
Patricia (30F) 

admin/homemaker 
real estate 
graphic design 
art instructor 
cafeteria mgr, dad 
retired ballet coach 

marketing 
 

Occupation 
stock trader 
HS teacher 
magazine editor 
salesman 
chef 
IT worker 
academic 
tech consultant 
researcher 
IT Project Mgr  
financial security 
student 
481

Name 
Myung (74M) 
Youngsook (62F) 
Kyungmi (50F) 
Jongho (51M) 
Kahee (28F) 
Dohyun (23M) 
Inseok (24M) 
Kiyoung (26F) 
Leemin (23M) 
Kitae (24M) 
 
 

Occupation 
oriental doctor 
housekeeper 
homemaker 
academic 
Ph.D Student 
asset mgmt. intern 
consultant 
research analyst 
startup founder 
between jobs 
 
 

CSCW '16, FEBRUARY 27–MARCH2, 2016, SAN FRANCISCO, CA, USA

Most  of  our 
interviewees  were  active  cloud  users, 
intentionally  spreading  their  data  across  different  systems. 
They expressed different rationales for their choices, from 
convenience to privacy. For Kyung-mi, cloud services were 
a  third  party  access  point  between  otherwise  incompatible 
device ecosystems [22,45]. For Boris, a university professor 
in  his  early  forties,  spreading  his  data  across  distinct 
services was a way of  “diversifying your identity between 
several  different  services”  that  “mitigates  your  exposure.” 
People  often  used  multiple  systems  and  services  for  the 
same activity, like listening to music or watching movies or 
TV shows, yet always with a context-specific narrative as to 
why and when these services were used. Ivory, a housewife 
in  a  Bay  Area  suburb,  described  her  home  entertainment 
system  that  included  subscription  services  to  HuluPlus, 
Netflix,  and  Chromecast,  and  explained  how  she  kept  a 
single iPod solely dedicated to playing music and videos in 
the  car.    And  Lisa,  a  New  York  City  professional,  used 
Spotify on her computer but iTunes on her phone, because 
“if you want to use [Spotify] on the phone, you have to pay 
for it, so I prefer to use my iTunes music on my phone.” 
As  a  result  of  their  engagement  with  multiple  systems, 
individuals’ data maps reflected not only many devices, but 
also  many  overlapping  networks  of  operating  systems, 
apps, and services (Fig. 1). Because no digital device comes 
“without its world” [13, p.137] and a concomitant array of 
cables, cloud services and other ecosystem accouterments, 
individuals were constantly engaged in a task of bricolage 
as 
their  unique,  heterogeneous  data 
systems.  Hence  all  our  interviewees  expressed  difficulties 
with the map-drawing exercise as their multi-service, multi-
device,  semi-cloud-based  systems  often  exceeded 
the 
capacities  of  the  two-dimensional  page.  Although  they 
described  each  data  system  with  a  clear  rationale, 
interviewees frequently struggled to find a visual language 
to  express  varying  levels  of  connectivity  across  devices, 
platforms, and shared services. Arrows and lines sometimes 
did the trick, but a few subjects started over to depict their 
system  in  way  that  took  this  “multiplexity”  [12]  into 
account. Boris began by drawing his different devices and 
their  connections  to  each  other,  but  soon  turned  over  the 
page  to  start  afresh,  drawing  a  set  of  radial  layers  of 
corporations and their servers, accessed to varying degrees 
by a series of devices (Fig. 2). 
Across their various ecosystems, our participants continued 
to  view  themselves  primarily  as  an  individual  user.  They 
would  set  up  their  services  and  configure  their  settings  in 
ways  that  they  believed  to  be  coherent  with  how  they 
thought of their data and devices: as personal. Yet as their 
data narratives and maps unfolded, they described how their 
personal data was enrolled in relational practices. We thus 
repeatedly  observed  a  tension  between  users'  work  to 
individually  determine 
their  own  data  management 
practices,  and  the  fact  that  much  of  their  data  was  being 
shared  among  and  affected  by  a  network  of  relationships 
[24,26] including friends, colleagues, and companies. 

they  assembled 

482

interpret 

interviewees 

RELATIONSHIPS AT STAKE 
All of our respondents were actively engaging in a digital 
form of relational work to digitally maintain their personal 
and  professional  networks  [20,32].  By  relational  work  we 
draw  on  sociologist  Viviana  Zelizer’s  definition  that,  “for 
each  distinct  category  of  social  relations,  people  … 
designate  certain  sorts  of  economic 
transactions  as 
appropriate  for  the  relation,  bar  other  transactions  as 
inappropriate,  and  adopt  certain  media  for  reckoning  and 
facilitating economic transactions within the relation” [47]. 
Thus,  participants  designated  and  performed  “appropriate” 
data  transactions  as  part  of  their  relationship  with  other 
people  and  companies.  As  in  Communication  Privacy 
Management  (CPM)  theory,  we  found  that  “implicitly  or 
explicitly,  family  members  functioning  as  recipients  are 
perceived  as  having  a  responsibility  for  information  that 
other members reveal to them or to whom they give access” 
[29,  p.177];  however,  they  did  not  seek  autonomy  from 
those  relationships.  We  therefore  investigate  the  ways  in 
which  our 
the  dimensions  of 
responsibility along which families, friends and companies 
understand  and  evaluate  their  identities,  relationships  and 
situations using data curation and exchange.  
For instance, Terry, a California stay at home mother of two 
adolescent  girls,  quite  literally  illustrated  the  relational 
work that goes into managing both her family members and 
their multiplicity of devices and systems at the same time. 
Her  data  map  began  with  placing  family  members  in  a 
family tree (Fig. 3), then adding each member’s devices and 
interoperability  constraints  and  the  data  moving  between 
them:  for  example,  the  parents  use  Android  and  Samsung 
devices while their daughters use Apple products. She uses 
Google  calendar  to  coordinate  family  commitments  both 
because, as she put it, it allows her to receive a notification 
that a family member has accepted an invitation, and helps 
her  to  sidestep  Apple/Android  interoperability  constraints. 
Such  practices  all  help  her  to  bridge  communication  gaps 
and  device  seamfulness  [4]  in  her  family  ecosystem  to 
ensure the smooth running of her household. 
Terry  also  designates  different  media  –  shared  calendars, 
social  media,  screen  captures,  and  wireless  speakers  –  for 
reckoning and facilitating interactions within her family and 
friendship circles. She keeps an eye on her kids by joining 
the social media site that they use, and shares screenshots of 
their  grades  with  her  husband  to  spare  him  the  hassle  of 
logging into the school’s online portal. She builds playlists 
– sometimes from lists solicited from her daughters – that 
play  through  a  Sonos  sound  system  that  creates  separate 
zones 
in  her  household  with  different  sounds.  Any 
household  member  can  control  the  system,  such  that  her 
husband  no  longer  bothers  the  rest  of  the  family  by 
streaming  baseball  games  while  the  younger  daughter  can 
host a birthday party outdoors with her own uninterrupted 
playlist. This use of shared music data to create boundaries 
contributes to the relational work of the household.  

SESSION: MUSEUMS AND PUBLIC SPACES

While  the  combination  of  these  solutions  may  not  seem 
technically  obvious  (especially  given  her  starting  point  of 
four  separate 
family  members  with  distinct  device 
preferences),  Terry’s  home  data  ecosystem  grew  around 
making connections between the devices for optimal intra-
family  communication,  coordination,  and  boundary  work. 
Indeed, because relational maintenance was so important to 
our  participants,  they  often  adopted  specific  systems 
because  of  those  relationships.  Terry  got  on  Facebook 
because  that  system  was  “the  original  one  that  I  saw  the 
children using,” although now that her children moved off 
the platform she uses it primarily to keep in touch with her 
own friends. Dave the chef also explained, “everybody who 
I  got  on  Facebook  I  was  in  elementary  school  with”  and 
describes the site as “who’s who and who’s hot and who’s 
not,  who’s  divorced  and  who’s  married  and  [who  has] 
kids.”  People  felt  social  pressure  to  join  a  data  curation 
service  from 
these  same  networks.  Research  analyst 
Kiyoung  described  her  dislike  for  some  of  KakaoTalk’s 
limited privacy features but stated, “then I came to Korea 
so I had no choice but to join.” An IT professional, Daniel 
had a strict preference for pseudonyms on social media, but 
he joined Facebook due to peer pressure. The tension of his 
own proclivity to safeguard his data with his desire to join 
his friends resulted in particularly strong affective reaction: 
“I’m  a  little  bit  bitter  about  it  because  the  person  that 
finally I guess broke me down ended up quitting Facebook 
and deleting the account. I’m really remorseful about it.” 
Corporate relationships 
Data-based relationships were not only salient in the home 
or  among  friends:  companies  were  surprisingly  visible  to 
our  respondents,  who  spoke  with  confidence  about  their 
device choices in terms of corporations and their products’ 
performances, or their optimization for specific tasks. This 
highlighted to us the salience of not just users’ relationships 
with other people, but also with the corporations supplying 
their device ecosystems. For example, Kyung-mi explained 
that she took up Ndrive, Naver, and Dropbox because they 
offered  large  amounts  of  disk  space  for  free  with  the 
purchase of a Samsung device, but eschewed Google Drive 
because it didn’t offer as much space.  

in 

their  homes.  Perhaps  because  of 

Individuals often associated data-management services with 
particular  companies  too.  Dave  explained  that  he  steered 
clear of PC’s “Because PC’s are like having children. They 
catch  colds.  They  need  to  be  medicated  and  if  you  don’t 
medicate them you better buy a new one… Have you tried 
to put something illegal on your phone or your computer? 
Apple  it’s  gonna  warn  you  three  to  four  times  like,  ‘what 
the  ‘F’  are  you  doing?’”  Of  course,  this  description  was 
consistent with Dave’s Apple-only hardware system; but a 
similar  interest  in  security  motivated  IT  worker  Daniel  to 
avoid Apple and Microsoft altogether and use Debian and 
free software instead, because “it is possible to inspect all 
the source code of the things that are running to make sure 
that there are no obvious security problems.” 
Corporate  actors  can  also  involve  the  state.    Because 
national  banking  and  payment  systems  in  Korea  require 
Internet Explorer and do not support other browsers, all the 
Koreans we interviewed kept a PC or Windows-compatible 
computer 
this 
association between financial data and PC’s, Koreans think 
of  PCs  as  their  “secure”  devices.  As  Kyung-mi,  the 
housewife  with  nine  devices,  put  it,  “my  PC  is  mostly  for 
payments and transactions. I really just still use it because 
of  that,  for  security,  things  that  need  to  be  completely 
secure, like transactions or banking.” State actors can also 
prevent the access of particular data or systems, as one of 
our  Korean  interviewees  expressed  when  he  lamented  the 
restrictions on online pornography in the country. 
Managing the network. 
The  above  examples  demonstrate  how  other  people  and 
actors influenced individuals’ systems and choices. This is 
consistent  with  the  “networked  privacy”  model  advanced 
by  Marwick  and  boyd  [24],  in  which  individuals  are 
embedded in a network of other actors whom they must not 
only  act  to  manage,  but  who  are  also  active  upon  them. 
Networked systems may frustrate individual users’ attempts 
at  data  management,  whether 
through  posting  or 
commenting systems open to users’ friends and family [24], 
using personal data to produce advertising preferences [33], 
or  changes  to  cloud-based  documents  [28].  Similarly 
participants  described  the  challenges  of  data  management 

Sample data maps from interviews 

From left-to-right: Fig. 1: Lisa’s map describes how various kinds of personal data moves between her devices, using various 

services and apps, with flows designated with arrows; Fig. 2: Boris draws his data, cloud services, and devices radially to express 
how data mediates his relationships to corporate actors, engaged in their own relational management; Fig. 3: Terry’s map places 
data within a family tree, reflecting how data, service and device management produces boundaries and relationships in the home. 

 

483

CSCW '16, FEBRUARY 27–MARCH2, 2016, SAN FRANCISCO, CA, USA

as  a  personal  responsibility  despite  an  unruly  network  of 
family members, friends, colleagues, and corporations. 
For example, Stan is a 25 year-old high school teacher in an 
inner city parochial school, who works hard to maintain a 
firm line between his personal and professional life, unlike 
his  curious  students.  While  Stan  tries  to  keep  his  online 
identity private, using pseudonyms and aliases for personal 
services,  he  still  worries  that  a  privacy  slip  up  might  cost 
him his job. The only service he posted his real name and 
photo on was LinkedIn when he was looking for a job, but 
he  was  understandably  startled  when  all  his  students 
changed  their  profile  picture  on  their  school  SNS  to  his 
LinkedIn profile picture as a prank.  
Harry,  a  party  magician,  shares  his  magic  trick  tutorials 
online with other magicians. Since magicians do not share 
their  secrets  with  non-magicians,  he  did  not  make  them 
public  or  on  YouTube.  He  did,  however,  set  up  a  shared 
Dropbox folder with his magician girlfriend, where he put 
some  of  the  trick  videos.  He  felt  surprised  and  betrayed 
when his girlfriend invited others to the folder. IT worker 
Daniel’s discomfort with Facebook, mentioned above, only 
increased  when  a  friend  began  uploading  and  tagging 
photos of him from the 1990’s to the system. Here, curated 
data  sharing  with  specific  individuals  or  communities  can 
be overturned by these same networked ties, either through 
malicious  intent,  as  in  the  case  of  Harry’s  ex,  or  through 
unintentional carelessness of a friend with different privacy 
sensibilities. 
Many individuals also felt responsibility on their own part 
to  protect  others  in  their  network.  An  avid  blogger  and 
fantasy  football  player,  Ulysses  described  his  online 
activities in decidedly relational terms, highlighting his ties 
to these communities: “I play flag football and I also write 
about the league itself. Keeps me busy and it’s good for the 
league. Keeps people interested.”  At the same time as he 
actively  promoted  and  encouraged  public  conversation 
around his hobby to manage relationships in among the flag 
football community, Ulysses drew strict boundaries around 
anything  that  involved  his  kids  or  family.  He  therefore 
preferred  to  avoid  using  cloud-based  or  public  internet 
services  to  share  or  store  that  data.  As  a  father  of  two  he 
reported  “quarrels”  with  his  wife  about  "the  amount  of 
pictures [sic] she puts up [on the internet], my children’s 
especially. You want to put my, you want to splatter my ugly 
face  on  the  Internet  [then  go  ahead].  I  personally  would 
like  for  the  kids  to  make  that  decision  on  their  own.”  We 
also saw similar concerns amount those who weren’t trying 
to protect their own family members. Kahee initially stated 
that  he  did  not  have  any  concerns  about  the  fact  that  his 
devices were all unlocked, saying “I don’t have anything to 
hide.”  But  he  later  reconsidered,  “I  have  other  people’s 
contact information in here, all of my friends. If I consider 
them, I should be locking my devices with passwords.”   
This  points  to  an  essential  tension  around  personal  data 
management  that  surfaced  repeatedly  in  our  interviews: 

484

tension  between 

these  contradictory 

between  the  responsibility  to  share  data  as  part  of  an 
ongoing  relationship,  and  the  responsibility  to  safeguard 
that  same  data  from  unpredictable  harms  to  protect  that 
relationship.  Many  CSCW  papers  on  data  management  or 
sharing  have  examined  these  elements  in  situ,  usually 
associated  with  one  or  another  platform, 
service, 
community,  or  identity:  working  to  manage  “context 
collapse,”  for  instance,  or  using  Goffman’s  dramaturgical 
framework of self-presentation [i.e.15,23,43]. Yet it was in 
the 
imperatives, 
experienced  across  multiple  overlapping  and  contradicting 
systems  and  relationships,  that  we  glimpsed  the  moral 
economy of data management in action. 
For instance, consistent with our findings about the role of 
the  company  as  an  actor  in  users’  relational  networks, 
individuals  frequently  thought  first  about  the  corporations 
involved, not just their friends or family, before uploading 
personal data to a service or syncing to the cloud. Kyung-
mi  described  feeling  “anxious”  because  corporate  systems 
like Google or Naver are “run by companies, so they can be 
exposed  by  the  company’s  mistakes  or  whatever…  I  don’t 
know how well they back things up.” This led her to set up a 
“double-backup”  system  between  external  hard-drives  and 
Dropbox  folders.  Some  of  our  interviewees  even  tailored 
their data production on the front end, in line with the way 
they  expected  it  might  be  distributed  online.  Ivory,  the 
homemaker  with  a  multi-service  home  entertainment 
system, was an extensive documenter of her children’s lives 
and  regularly  posted  home  videos  to  YouTube.  But  she 
insisted, “I never do anything like the bath time stuff. That’s 
just -- we don’t even take videos of that.”  
The  decision  to  entrust  one’s  personal  data  to  a  company 
was  entangled  with 
the 
likelihood that companies might share this personal data as 
part  of  their  own  corporate  relational  work.  For  example, 
one New York IT consultant used specific email addresses 
for each company he registered with, and confronted one of 
them when an email address he used only for one financial 
institution  began  receiving  third  party  spam.  Another 
described  how  corporate  interconnections  affected  her  use 
of services: “I feel like there’s a lot of information that I’m 
willing to give to one app or one company, but I don’t like it 
to  be  related  to  what  I’m  giving  to  another  company…  I 
have  an  Instagram  account  and  I  keep  it  private  not 
because I care about people I don’t know seeing my photos 
… [but] because I don’t like that other companies just pull 
up all the public photos on Instagram and use them for lots 
of different kinds of things. I don’t like the idea of what a 
third party might do with it.” 
Data  narratives  like  these  deploy  emotional,  normative 
language. But they are not about the management of face or 
the awkwardness of self-presentation. Instead, they expose 
a  concern  that  an  individual’s  data  might  travel  between 
entities  with  whom  they  have  no  pre-existing  relationship. 
Recall how Boris, the university professor, drew up his data 

individuals’  discomfort  with 

SESSION: MUSEUMS AND PUBLIC SPACES

map and narrated his practices, depicting both the layers of 
relationships between himself, his devices, his services, and 
the  underlying  relationships  between  companies  providing 
those  services.  Hence  his  practice  of  what  we  call  “data 
balkanization”:  spreading  his  personal  data  across  many 
distinct online systems. For Boris at least, fragmenting his 
identity  across  systems  produced  a  kind  of  privacy  from 
corporate actors for practical purposes.  
MORAL CONSIDERATIONS 
The “right” tools for the job 
Even  with  so  many  device  ecosystems,  our  participants 
accounted for their systems with a high degree of certainty. 
They described their setup with words like “of course” and 
“obviously”,  betraying  a  sensibility  that  their  system  was 
built on principles that “anyone like us necessarily knows” 
their  work  of data management  was 
[8].  Certainly 
purposeful and  practical  work, 
locally  achieved  with 
devices  and services  ready  to  hand.  It  was  also  a  form  of 
emotional labor, tied to practices of relational maintenance, 
as we have described. However, we were also struck with 
how frequently their data narratives betrayed a confidence 
that  they  were  "doing  it  right."  When  we  asked  our 
interviewees  how  they do manage  their  data,  they  often 
responded that it was how one should manage their data. 
At  the  intersection  of  these  many  devices  and  services, 
communities  and  corporations,  then,  our  interviewees 
reached  for  a  morally-laden  language  to  describe  the 
rationales  that  guided  their  technological  choices.  This 
again  distinguishes  our  analysis  of  their  narratives  from 
work that focuses on a dramaturgical perspective. While the 
latter  has  successfully  been  applied  to  online  contexts  to 
“explain  how  an  individual  presents  an  ‘idealized’  rather 
than  authentic  version  of  herself”  [15:  p.378],  it  does  not 
investigate  motivating  articulations  of  selfhood.  But  the 
data  narratives  we  heard  presented  a  more  normative, 
perhaps aspirational, sense of self in which actions (such as 
data  management  or  photo  sharing)  reflect  a  true  or 
authentic  “good”  self.  This  differs  from  accounts  of  how 
data 
site 
maintainers”)  can  be  good  or  bad,  successful  or  not,  but 
does  not  express  anything  about  the  personal  choices  of 
those whose data has been curated [15]. 
Our  interviewees  did  not  describe  performances  for  an 
audience,  visible  or  invisible.    Instead  they  were  keen  to 
enact  the  identity  of  a  good  daughter  through  the  actions 
that  constitute  being  a  good  daughter,  including  locally-
appropriate norms of sharing or protecting. They frequently 
negotiated  competing  and  even  incompatible  priorities  in 
practice:  sharing  with  the  right  actors  versus  safeguarding 
data  from  others,  for  instance.  Yet  they  brought  these 
elements together into a unifying narrative about “the best 
way”  to  combine  the  right  devices  and  services  with  the 
appropriate  communities  of  individuals  or  companies:  a 
valuable,  responsible,  and  appropriate  way  to  manage 
personal data, whether "technically" correct or not.   

“algorithms  designed  by 

curating 

(via 

This aspect of the data narrative was especially clear when 
our  interviewees  explained  why a  particular  device  or 
service was the right one for a particular activity, such as a 
computer,  phone,  or  tablet  specifically  for  work,  for 
children, or for use only in the car. As Ivory described the 
division  of  labor  between  her computer,  iPhone  and  iPad: 
“Computer is picture/video storage. The iPhone is on-the-
go  web  searches,  like  if  I'm  looking  for  an  address  or 
something… we watch TV with the iPad [and…] [the kids] 
listen  to  songs  and  movies  in  the  car.”  Given  Ivory’s 
curation  of  photos  and  videos  to  share  with  extended 
family,  the  shared  desktop  was  a  family  workspace,  the 
iPad  was  a  media  device  used  either  with  her  husband  to 
unwind or to pacify the kids during their commute, and her 
phone  enabled  her  own  on-the-go  schedule.  Daniel,  our 
open-source  advocate,  used  non-free  tools  as  part  of  his 
volunteer  work  for  a  non-profit  organization:  an  activity 
that he felt was as morally responsible as his commitment 
to open-source. A magazine editor we interviewed uploaded 
almost everything to the cloud but took care to keep his and 
his  wife’s  intimate  photographs,  recordings,  and  videos 
only on local devices. As they mixed and matched devices, 
services,  and  data  with  different 
relationships  and 
situations, our participants’ choices aimed to draw different 
socially- and morally-valent boundaries around their many 
practices, interactions, and relationships.  
This was also evident in our interview with a Korean army 
veteran  who  explained  how  the  experience  had  eradicated 
his personal boundaries: “Once I got back from the army I 
think  my  need 
for  privacy  disappeared.  You  share 
everything; you don’t have your own personal space. Here 
at  work,  too,  we  all  leave  our  Facebooks  on  and  when 
someone’s  out  we  read  all  of  their  messages  and  stuff. 
There’re  no  secrets.  I’m  just  so  used  to  that  kind  of 
culture.” Enrolled in and producing a different set of social 
and moral orderings, he drew just as few distinctions with 
his data, devices and services as he did in his personal life. 
Thus  our  interviewees’  systems,  as  idiosyncratic  as  they 
appeared  on  the  surface,  were  each  shot  through  with 
intentionality and a local sense of right and wrong.   
Indeed, the evaluative, normative, and emotionally-charged 
language  that  our  interviewees  used  to  describe  both  their 
systems  as  a  whole  and  their  own  actions  frequently 
surprised us. Recall that when Kyung-mi described mixing 
and matching iOS and Android devices and capabilities, she 
said, “If you’re good at these things you’ll succeed.” Dave 
explained that he used Apple products not only for Apple's 
particular  virtues  but  also  because  he  wanted  to  "do  it 
right."  Daniel  was  adamant  that  he  would  only  use  open-
source  software  not  only  for  security  reasons  but  also 
because  it  was  the  right  thing  to  do,  visible  too  in  his 
“remorse” and “bitterness” at having joined Facebook. As 
the  morally-charged  language  of  "doing  it  right"  and  the 
"success" that results from an appropriately-constructed and 
maintained  system  reverberated  across  our  interviews,  we 
witnessed  a  strong  link  between  data,  device  and  service 

485

CSCW '16, FEBRUARY 27–MARCH2, 2016, SAN FRANCISCO, CA, USA

the 

to  manage 

the 

right 

technologies 

management on the one hand and relationship and boundary 
management  on  the  other,  the  efficacy  of  which  reflected 
either positively or poorly on the individual as a whole.  
Fears and complacencies 
When  we  asked  our  participants  to  describe  their  fears 
about  their  data,  their  answers  expressed  another  essential 
tension at the heart of their data management techniques. If 
the  performance  of  appropriate  data  management  is  a 
question  of  assembling  a  morally-accountable  system  -- 
using 
right 
relationships in the right ways to “succeed” or “do it right” 
-- then the fears individuals expressed were of upsetting or 
otherwise  interrupting  this  delicate  work  of  ordering. 
Because  of  these  associations,  upsetting  this  balance  was 
for them a social and a moral problem, not a technical one.  
Some externalized their fear of system destabilization in the 
form  of  “hackers.”  One  interviewee  changed  all  his 
passwords every three months, emailing himself a hint for 
the new password as a mnemonic, another claimed to check 
his bank account “three or four times a day …just to make 
sure  that  no  one  is  stealing  anything  or  something  like 
that.”  Yet  even  if  no  “hacker”  was  involved,  there  was  a 
general unease about information being “out there.” As flag 
football  blogger  Ulysses  put  it,  “It’s  the  distrust  of  the 
unknown…  Once  it’s  out  there,  how  do  you  get  rid  of  it? 
How’s  it  being  used?  …  Once  it  slips  your  phone,  you’re 
done.  It’s  no  longer  yours.”  The  magazine  editor  made 
reference to the movie Sex Tape to explain his fear: “I am 
afraid that our personal videos, as the movie, will end up 
on  Google  Drive  or  something  weird  somewhere  by 
accident,  because  I  just  have  it  on  the  iPad.”  And  Terry 
was  concerned  about  what  would  happen  if  her  children’s 
personal photos or files that they shared with their friends 
or posted on file storage services were taken out of context. 
She pointed to stories she had heard of teens being shamed 
at  their  schools  when  nude  photos  circulated  among  their 
social  circle.  “These  are  nice  families,  nice  girls...  it 
happens in every community.” 
The  fears  our  interviewees  expressed  did  not  drive  their 
practices,  nor  were  they  linked  to  particular  values  [as  in 
16].  People  who  were  afraid  of  data  security  online  were 
not  more  likely  to  adopt  what  we  might  identify  as  more 
secure  systems,  although  they  might  keep  paper  files  in  a 
safety  deposit  box  or  hide  their  Wi-Fi  SSID.  Those  who 
were afraid of hacking often auto-saved their passwords and 
did not lock their phones; those with concerns about Google 
still often used Chrome or Android. One interviewee didn’t 
backup  photos  online  to  avoid  a  leak,  but  he  put  them  on 
Facebook  with  tags  and  privacy  settings  nonetheless. 
Another  simply  explained  that  he  was  proficient  enough 
with  computers  that  he  would  know  if  he  were  being 
hacked, so he took no precautions against an attack. 
However, individuals frequently worried that they could not 
control the people [as in 45] and companies in their network 
to  appropriately  share  and  safeguard  their  data.  Many 

feared  that  a  company  would  change  a  system  such  that 
their set-up no longer worked, or implement a new feature 
that might go rogue and leak data. Hence the IT consultant 
in New York explained his choice of devices and services 
in  terms  of  a  data  narrative  about  company  philosophies: 
“Of  Google,  Apple,  Twitter  and  Facebook,  I  really  only 
place some amount of trust in Apple, and the reason for that 
is that I feel like I am Apple's customer, whereas I feel like 
Twitter,  Facebook  and  Google,  their  customers  are  ad 
buyers and I'm actually their product, what's being sold, so 
the  relationship  that  I  have  with  those  three  companies  is 
one where I don't trust them to do what's in my interest.” A 
corporate  shuffle  or  a  design  tweak  could  also  violate  the 
norms  of  safeguarding  or  sharing  in  a  given  relationship. 
For example, the Korean messenger application Kakaotalk 
automatically  adds  individuals  to  each  others’  friend  lists, 
sometimes before they have even met. One user described a 
negative experience with the function: “Recently I agreed to 
go on a blind date. I got her number. But then when I saved 
the  number  her  KakaoTalk  profile  picture  showed  up  and 
then  that  means  I’ll  show  up  on  hers  too,  right?  That’s 
pretty unpleasant.” Individuals could also upset this careful 
moral  economy,  as  in  Ulysses’  arguments  with  his  wife 
over  sharing  family  photos. Ultimately,  we  were  surprised 
that  fear  of  system  change  or  unintentional  relational 
violation was a more prominent factor than fear of data loss 
in these data narratives. Given the importance of “doing it 
right,”  a shift  in  one  component  system would  upset  the 
entire balance, precariously and continuously achieved.  
THE MORAL ECONOMY OF DATA MANAGEMENT 
Our  interviewees  described  idiosyncratic  combinations  of 
devices,  systems,  and  relationships  that  comprised  their 
data  ecosystems,  unified  under  what  they  identified  as 
commonsense  rules  about  how  to  put  these  elements 
together  in  “the  right  way.”  We  describe  these  competing 
tensions  and  local  ways  of  resolving  them  as  a  moral 
economy of data management. This terminology expresses 
the complexity, ongoing tradeoffs, attempts at balance and 
above all the weighty emotional and reflexive components 
of what may seem like logical, technical, or even financial 
decisions.  While  moral  economies  combine  a  set  of  local 
practices  with  larger  sense-making  narratives  that  render 
those  practices  locally-accountable in  just  the  right  ways, 
this  does  not  mean  that  there  is  a  single  “right  way”  to 
manage  personal  data.  Instead,  this  use  of  “right”  or 
“wrong”  reveals  the  strong  normative  values  that  people 
describe  in  reference  to  what  they  do  and  why,  and  their 
sense  that  others  are  judging  their  performance  by  these 
metrics. By doing data management well, they aspire to the 
virtues  of  responsible  people,  parents,  colleagues,  and 
friends.  To  do  so,  they  bring  together  tools  and  objects, 
social  relations,  and  a  heightened  sensibility 
the 
appropriate or right way to assemble these pieces.  
Even  though  we  are  concerned  with  what  our  participants 
identify  as  “doing  it  right,”  we  do  not  aim  to  solve  the 
technical hurdles they faced to produce perfectly seamless 

to 

486

SESSION: MUSEUMS AND PUBLIC SPACES

the 

the  underlying  mechanisms  of 

right  people,  whether  colleagues, 

data systems. Instead, we consider how their “right way” to 
do  data  management  is  tinged  with  specific  tensions  and 
even  impossibilities  in  balancing  competing  interests, 
needs,  and  resources  [6].  These  tensions  are  important  for 
identifying 
the  moral 
economy  itself.  Indeed,  the  data  narratives  we  analyzed 
exposed the two related and arguably incompatible tensions 
at  the  heart  of  the  moral  economy  of  data  management: 
between  sharing  and  safeguarding,  and  between  the 
responsible individual and the networked self.  
Balancing tensions 
At the intersection of their devices, their services, and their 
social relations, users are engaged in a balancing act. On the 
one  hand, they  are  balancing  their  relational  work  to 
individuals  and  companies in  their  extended  personal, 
professional, and consumer networks. This is visible in the 
wide variety of services that they adopt to share data with 
just 
friends, 
spouses, or  online  services.  Each  device,  system,  and  data 
storage  solution  that they  choose  is  a  function  of  and 
produces a particular relationship. For example, the parents 
we interviewed were using Shutterfly, YouTube, or email to 
send  family  photos  to  their  relatives.  Sharing  moments 
with family  was  an  important  way  to  be  not  only  a  good 
parent, but also a good family member [19]. Even systems 
chosen  for  “convenience”  or  “comfort”  conformed  with 
specific relational ties and goals, allowing them to share the 
right data with the right people at the right time. If not, they 
would not be considered quite so convenient! 
On  the  other  hand,  individuals  are  balancing  a  conflicting 
moral imperative to safeguard this data and to share it only 
in  responsible  ways.  Terry’s comment,  “These  are  nice 
girls!”  or  Ulysses’  reticence  to  put  his children’s  photos 
online  are  expressions  of  this  imperative.  This  personal 
responsibility  was  keenly  felt.  Many  of  the  fears  that 
our participants  discussed  above  about  their  data  privacy 
could  be  traced  to  this conflict  between  competing  moral 
expectations of individual data protection on the one hand, 
and  maintaining 
ties 
through sharing  on  the  other.  Ironically,  the  requirement 
to safeguard  was  expressed 
the  very  same 
instruments and technical practices as the moral imperative 
to  share,  to  belong, and  to participate  in  existing  networks 
of friends, colleagues, and corporate relations. 
Individual responsibility for data 
The moral economy of data management not only involves 
negotiating the tension between safeguarding and sharing: it 
also  requires  balancing  these  two  competing  and  even 
incompatible  norms  as  an  individual  responsibility  in 
relationships,  device 
the face  of  shifting interpersonal 
ecosystems, 
philosophies.  Here, 
the individual’s  keenly-felt  moral  imperative  to  manage 
their data appropriately often came into direct conflict with 
the reality of a networked system that extends beyond their 
control [24,45]. No wonder, then, that the spectrum of fears 

their 

relational 

and 

social 

through 

and 

corporate 

that  our  interviewees  described  laid  out  how  the  activities 
of  unpredictable  and  unruly  others  might  disrupt  or  break 
their  carefully  assembled  systems.  This  would  make  them 
out  to  be  not  only  bad  stewards  of  their  data  or  simply 
technically  inept,  but  even  bad  or  irresponsible  friends, 
family members, or consumers. 
This was especially visible when our respondents described 
how  the  same  action  –  say,  sharing  a  video  –  could  be 
moved  from  a  positive  action  to  a  negative  action  rapidly 
with  an  unpredictable  shift. For  example, Ivory  took  great 
care to generate a photo and video library of her two young 
children,  which  her  husband  carefully  curated,  titled,  and 
organized.  In  a  performance  of  good  parenthood,  Ivory 
regularly  shared 
the  photos  and  videos  with  her 
international  family  members  using  a  blog  and  YouTube, 
much as reported in [19]. But when one innocuous video of 
her  children  rolling  a  ball  back  and  forth  to  each  other 
garnered 200,000 views within a short span of time, Ivory 
panicked  that  the  same  action  (sharing  baby  videos)  was 
transformed  from  an  act  of  good  motherhood  to  one  of 
irresponsible parenting. Recall, too, how Harry’s sharing of 
his magic videos with his inner circle was suddenly recast 
as  a  breach  of  the  magician’s  social  contract  when  his 
girlfriend shared those same videos in turn.  
While our respondents articulated clear "right" and "wrong" 
ways for to fulfill their various and even conflicting roles, 
this is not to say that there is a universal way of “being a 
good  parent”  (or  a  good  magician,  or  teacher)  online.  In 
fact, our respondents frequently offered mutually exclusive 
examples  of  what  “being  good”  could  look  like.  Ulysses 
posited  that  it  meant  allowing  your  children  to  decide  for 
themselves  whether  or  not  they  wanted  their  personal 
likeness  online,  whereas  for  his  wife  (and  Ivory)  it  meant 
sharing photos of your children with others who care about 
them.  Even  if  the  actions  are  not  the  same,  what  is 
generalizable  is  the  normative  evaluation  of  these  actions, 
thoroughly considered by our respondents. Whether parent, 
teacher, spouse, or magician, their data narratives expressed 
the belief that there is a good, responsible, and appropriate 
way to manage one's online data associated with that role, 
and  obvious  wrong  ways  to  do  so.  To  this  end,  the  data 
narratives that we heard exposed the moral economy of data 
management: an overarching association of local practices 
that  balance  irreconcilable  tensions  on  the  one  hand,  with 
“rightness,” “success,” and personal propriety on the other.  
CONCLUDING IMPLICATIONS 
Talking  about  data  management  with  33  different 
individuals occupying different walks of life, social classes, 
technical  proficiencies,  and  countries,  exposed  as  many 
different  data  (and  device)  management  practices  as  there 
are  users.  Nonetheless,  commonalities  emerged  across  the 
data narratives we solicited, no matter how disparate their 
device  ecosystems,  their  technical  rationales,  or  their 
geographical  location.  Our  interviewees  each  expressed  a 
clear  and  integrated  rationale  for  their  choices  of  devices, 

487

CSCW '16, FEBRUARY 27–MARCH2, 2016, SAN FRANCISCO, CA, USA

in 

choices 

technological 

services,  and  data  management  practices.  They  were  all 
busy  balancing  their  social  obligations  to  share  their  data 
with their equal obligations to protect this same data. They 
also  narrated  a  heterogeneous  web  of  relationships  among 
which data circulated, including family, friends, colleagues, 
and  companies:  a  network  that  was  fragile  and  constantly 
threatened  with  breakdown.  And  in  the  midst  of  these 
various  tensions  and  complexities,  everyone  we  spoke  to 
was committed to doing it right.  
Ascertaining  this  shared  sensibility  allows  us  to  draw 
commonalities  among  everyday  users,  scientists, 
IT 
professionals, and homemakers. That is, it is not only teens 
[26]  and  new  mothers  [19]  who  are  carefully  balancing 
appropriate  levels  of  sharing,  safeguarding,  or  otherwise 
stewarding  personal  data  online.  The  data  narratives  that 
our  respondents  shared  indicate  that  these  are  overarching 
concerns  present 
across 
heterogeneous contexts of use and device ecologies.   
Further, the moral economy of data management, visible in 
these disparate data narratives, demonstrates how and why 
data  moves  among  relational  ties  in  locally-appropriate 
ways.  Data  sharing  is  indeed  complicit  in  social  relations: 
but not only during certain times of transition (such as death 
[3])  or  in  particular  circumstances  (like  offices  [45]  or 
collaboratories  [41]);  and  not  only  due  to  a  dramaturgical 
sense of identity management. Seeking out data narratives 
at  a  broader  level  reveals  the  unifying  accounts  and 
rationales  that  motivate  users  and  make  sense  of  their 
systems  and  choices  more  globally,  even  and  especially 
when narratives conflict with practical implementation. 
It  is  not  new  in  CSCW  to  extoll  the  virtues  of  data 
management  as  a  socially  enacted  practice  [7,24,29]  that 
involves  a  reasoned  combination  of  privacy,  sharing,  and 
everyday access activities in the moment and on the ground 
[28,45]. However, moving beyond this point, we argue that 
these  ideals  of  local  appropriateness  are  not  only  part  of 
managing social ties but are equally tied in with users’ work 
of social and moral ordering. The social ordering applies 
to  the  unique  combination  of  technologies  that  manage 
social  ties;  the  moral  ordering  describes  the  perceived 
relationship  between  “good  data  management”  and  “good 
personhood”  achieved  through  practice,  where  “doing  it 
right” and “being good” are locally ascertained. Further, our 
interviews  demonstrate  how  individuals  are  precariously 
assembling  these  elements  on  an  ongoing  basis,  even  as 
they draw strong ties between the proper assembly of these 
data  management  elements  and  their  sense  of  self  as  a 
responsible 
individual,  family  member,  employee,  or 
customer.  Attention to the fears associated with networks 
of  data  exchange  –  including  people  and  companies  – 
reveals  just  how  many  contradictory  elements  users  are 
trying  to  hold  in  the  balance  at  once.    No  wonder 
individuals think carefully and worry often about how they 
should  handle  their  data  to  manage  these  conflicting 
tensions  in  daily  life.  Conceptualizing  data  management 

within  a  framework  of  a  moral  economy  allows  us  to 
glimpse  these  conflicting  elements  in  everyday,  ordinary 
action,  and  better  understand  the  relationship  between  an 
individual’s  local  practices  and  their  keenly  felt  sense  of 
“good” selfhood. 
We  therefore  argue  for  a  renewed  appreciation  of  the 
acutely-felt  tension  between  sharing  and  safeguarding  on 
the  one  hand,  and  between  individual  responsibility  and 
networked  reality  on  the  other.  We  agree  with  [20,24,29] 
that too many current approaches to data management rely 
on  a  notion  of  individual  selves  in  full  command  of  their 
data systems; the moral economy framework demonstrates 
why  those  who  fail  to  properly  manage  this  expanding 
network  of  services  are  judged  due  to  their  own  techno-
moral  failing.  And  we  have  learned  much  from  scholars’ 
focus on the management of relationships to avoid “context 
collapse” or conduct “face work” in social interactions [i.e. 
15,22,43,44],  or  to  understand  the  complexities  of  sharing 
in  particular  situations  [i.e.  3,14,28,37,44,45].  However, 
this  study  demonstrates 
future  work  on  data 
management must equally address the reflexive, moral work 
that  people  are  doing and  the  essential  tensions  they  face 
when they are doing data management, in whatever context 
they  do  so:  professional  or  personal,  in  a  scientific 
collaboration or among a community of mothers. After all, 
it  is  this  moral  framework  and  associated  discourse  that 
shapes  both  practices  and  people.    Further  articulations  of 
the moral economy of data management across a variety of 
contexts  will  go  a  long  way  toward  producing  systems, 
regulatory frameworks, and choices that users can embrace 
with a sense of responsibility, and confidence that they are 
“doing it right.” 
ACKNOWLEDGMENTS 
We thank Yahoo for the Faculty Research and Engagement 
Program grant that funded our research, and the anonymous 
reviewers whose comments greatly improved this paper. 
REFERENCES 
1.  Louise Barkhuus. 2012. The mismeasurement of 

that 

privacy: using contextual integrity to reconsider privacy 
in HCI. In Proceedings of the SIGCHI Conference on 
Human Factors in Computing Systems(CHI '12). ACM, 
New York, NY, USA, 367-376. 
DOI=10.1145/2207676.2207727  

2.  Jeremy P. Birnholtz and Matthew J. Bietz. 2003. Data at 
work: supporting sharing in science and engineering. In 
Proceedings of the 2003 international ACM 
SIGGROUP conference on Supporting group work 
(GROUP '03). ACM, New York, NY, USA, 339-348. 
DOI=10.1145/958160.958215 

3.  Jed  R.  Brubaker,  Lynn  S.  Dombrowski,  Anita  M. 
Gilbert,  Nafiri  Kusumakaulika,  and  Gillian  R.  Hayes. 
2014.  Stewarding  a 
responsibilities  and 
relationships  in  the  management  of  post-mortem  data. 
In Proceedings  of  the  SIGCHI  Conference  on  Human 
Factors  in  Computing  Systems (CHI  '14).  ACM,  New 

legacy: 

488

SESSION: MUSEUMS AND PUBLIC SPACES

York, 
DOI=10.1145/2556288.2557059  

NY, 

USA, 

4157-4166. 

4.  Matthew Chalmers, Areti Galani, Seamful interweaving: 
heterogeneity  in  the  theory  and  design  of  interactive 
systems,  Proceedings  of 
the  5th  conference  on 
Designing  interactive  systems:  processes,  practices, 
methods, and techniques, August 1-4, 2004, Cambridge, 
MA, USA . 

5.  David Dearman and Jeffery S. Pierce. 2008. It's on my 
other  computer!:  computing  with  multiple  devices. 
In Proceedings  of  the  SIGCHI  Conference  on  Human 
Factors  in  Computing  Systems (CHI  '08).  ACM,  New 
York, 
767-776. 
DOI=10.1145/1357054.1357177 . 

USA, 

NY, 

6.  Lorraine  Daston.  1995.  The  moral  economy  of 

science. Osiris (10): 2-24. 

7.  Paul  Dourish  and  Ken  Anderson.  2006.  Collective 
information practice: emploring privacy and security as 
phenomena. Hum.-Comput. 
social 
and 
Interact. 21, 
319-342. 
DOI=10.1207/s15327051hci2103_2 

cultural 
3 

(September 

2006), 

8.  Harald  Garfinkel.  1967.  Studies  in  Ethnomethodology. 

New Jersey: Prentice Hall. 

9.   Bill  Gaver,  Tony  Dunne,  and  Elena  Pacenti.  1999. 
Design:  Cultural  probes. interactions 6,  1  (January 
1999), 21-29. DOI=10.1145/291224.291235  

10. Barney  Glaser,  and  Anselm  L.  Strauss.  1967.  The 
Discovery  of  Grounded  Theory:  Strategies 
for 
Qualitative  Research.  Hawthorne  NY:  Aldine  de 
Gruyter. 

the 

11. Rebecca  Gulotta,  William  Odom,  Jodi  Forlizzi,  and 
legacy: 
Haakon  Faste.  2013.  Digital  artifacts  as 
exploring 
lifespan  and  value  of  digital  data. 
In Proceedings  of  the  SIGCHI  Conference  on  Human 
Factors  in  Computing  Systems (CHI  '13).  ACM,  New 
York, 
1813-1822. 
DOI=10.1145/2470654.2466240 

USA, 

NY, 

12. Caroline Haythornthwaite. 2005. Social networks and 

internet connectivity effects. Information, 
Communication & Society 8(2): 125-147. 
13. Donna Haraway. 1997. Modest_Witness@ 
Second_Millennium. Routledge, New York. 

14. Richard  Harper,  Siân  Lindley,  Eno  Thereska,  Richard 
Banks, Philip Gosset, Gavin Smyth, William Odom, and 
Eryn Whitworth. 2013. What is a file?. In Proceedings 
of 
the  2013  conference  on  Computer  supported 
cooperative  work (CSCW  '13).  ACM,  New  York,  NY, 
USA, 1125-1136. DOI=10.1145/2441776.2441903 

15. Bernie  Hogan.  2010.  The  Presentation  of  Self  in  the 
Age  of  Social  Media:  Distinguishing  Performances  and 
Exhibitions  Online.  Bulletin  of  Science,  Technology  & 
Society 30(6): 377–86. 

489

16.  Joseph 'Jofish' Kaye, Janet Vertesi, Shari Avery, Allan 
Dafoe,  Shay  David,  Lisa  Onaga,  Ivan  Rosero,  and 
Trevor Pinch. 2006. To have and to hold: exploring the 
personal  archive.  In  Proceedings  of 
the  SIGCHI 
Conference  on  Human  Factors 
in  Computing 
Systems (CHI  '06).  ACM,  New  York,  NY,  USA,  275-
284. DOI=10.1145/1124772.1124814  

17. Karina  Kervin  and  Margaret  Hedstrom.  2012.  How 
research funding affects data sharing. In Proceedings of 
the  ACM  2012  conference  on  Computer  Supported 
Cooperative Work Companion (CSCW '12). ACM, New 
York, 
131-134. 
DOI=10.1145/2141512.2141560 

USA, 

NY, 

18. Robert  Kohler.  1991.  Drosophilia  and  evolutionary 
genetics:  the  moral  economy  of  scientific  practice. 
History of Science 29(4): 335-375.  

19.  Priya  Kumar  and  Sarita  Schoenebeck.  2015.  The 
Modern Day Baby Book: Enacting Good Mothering and 
Stewarding Privacy on Facebook. In Proceedings of the 
18th  ACM  Conference  on  Computer  Supported 
Cooperative  Work  &  Social  Computing (CSCW  '15). 
ACM,  New  York,  NY,  USA, 
1302-1312. 
DOI=10.1145/2675133.2675149 

20. Karen Levy. 2013. “Relational big data.” The Stanford 

Law Review, 66 (September 3, 2013): 73-79. 

21. Kevin Lynch. 1960. Image of the City. MIT Press. 
22. Cathy  Marshall  and  John  C.  Tang.  2012.  That  syncing 
feeling:  early  user  experiences  with 
the  cloud. 
In Proceedings  of  the  Designing  Interactive  Systems 
Conference (DIS  '12).  ACM,  New  York,  NY,  USA, 
544-553. DOI=10.1145/2317956.2318038  

23. Alice  Marwick  and  danah  boyd.  (2011).  I  Tweet 
Honestly, I Tweet Passionately: Twitter Users, Context 
Collapse,  and  the  Imagined  Audience.  New  Media  & 
Society 13(1):114–33. 

24.  Alice  Marwick  and  danah  boyd.  (2014).  Networked 
privacy:  How  teenagers  negotiate  context  in  social 
media. New  Media  & 
1051-
1067.doi:10.1177/1461444814543995 

Society 16(7): 

25. Patrick  McCray.  2000.  Large  telescopes  and  the  moral 
economy of recent astronomy. Social studies of science 
30(5): 685-711. 

26. Helena M. Mentis, Siân E. Lindley, Stuart Taylor, Paul 
Dunphy, Tim Regan, and Richard Harper. 2012. Taking 
as  an  act  of  sharing.  In Proceedings  of  the  ACM  2012 
conference  on  Computer  Supported  Cooperative 
Work (CSCW '12). ACM, New York, NY, USA, 1091-
1100. DOI=10.1145/2145204.2145366 

27.  Helen Nissenbaum. 2009. Privacy in Context: 

Technology, Policy, and the Integrity of Social Life. 
Stanford University Press, Stanford, CA, USA.  

28. William  Odom,  Abi  Sellen,  Richard  Harper,  and  Eno 
Thereska.  2012.  Lost  in  translation:  understanding  the 

CSCW '16, FEBRUARY 27–MARCH2, 2016, SAN FRANCISCO, CA, USA

possession of digital things in the cloud. In Proceedings 
of  the  SIGCHI  Conference  on  Human  Factors  in 
Computing  Systems (CHI  '12).  ACM,  New  York,  NY, 
USA, 781-790. DOI=10.1145/2207676.2207789 

29. Leysia  Palen  and  Paul  Dourish.  2003.  Unpacking
"privacy" for a networked world. In Proceedings of the
SIGCHI  Conference  on  Human  Factors  in  Computing
Systems (CHI  '03).  ACM,  New  York,  NY,  USA,  129-
136. DOI=10.1145/642611.642635

30. Sandra  Petronio.  2010.  Communication  Privacy
Management Theory: What Do We Know About Family
Privacy  Regulation?  Journal  of  Family  Theory  &
Review 2(3): 175–96.

31. William  Ryan,  Erik  Stolterman,  Heekyoung  Jung,
Martin  Siegel,  Tonya  Thompson,  and  William  R.
Hazlewood.  2009.  Device  ecology  mapper:  a  tool  for
studying  users'  ecosystems  of 
interactive  artifacts.
In CHI  '09  Extended  Abstracts  on  Human  Factors  in
Computing  Systems (CHI  EA  '09).  ACM,  New  York,
NY, USA, 4327-4332. DOI=10.1145/1520340.1520661
32. Irina  Shklovski,  Louise  Barkhuus,  Nis  Bornoe,  and
Joseph  'Jofish'  Kaye.  2015.  Friendship  Maintenance  in
the  Digital  Age:  Applying  a  Relational  Lens  to  Online
Social  Interaction.  In  Proceedings  of  the  18th  ACM
Conference  on  Computer  Supported  Cooperative  Work
&  Social  Computing (CSCW  '15).  ACM,  New  York,
NY, USA, 1477-1487. DOI=10.1145/2675133.2675294
33. Irina  Shklovski,  Scott  D.  Mainwaring,  Halla  Hrund
Skúladóttir, 
and  Höskuldur  Borgthorsson.  2014.
Leakiness  and  creepiness  in  app  space:  perceptions  of
privacy and mobile app use. In Proceedings of the 32nd
annual ACM conference on Human factors in computing
systems (CHI  '14).  ACM,  New  York,  NY,  USA,  2347-
2356. DOI=10.1145/2556288.2557421

34. Irina Shklovski and Janet Vertesi. 2014. Introduction to
transnational  HCI.  Human-

issue  of 

this  special 
Computer Interaction 29.1: 1-21.

35. Roger  Silverstone,  Eric  Hirsch  and  David  Morley.
Information  and  communication  technologies  and  the
moral  economy  of  the  household.  (1992)  In  Robert
(Eds.).  Consuming
Silverstone,  &  Eric  Hirsch 
technologies:  Media  and 
in  domestic
spaces. Psychology Press.

information 

36. Alex  S.  Taylor.  2011.  Out  there.  In Proceedings  of  the
SIGCHI  Conference  on  Human  Factors  in  Computing
Systems (CHI  '11).  ACM,  New  York,  NY,  USA,  685-
694. DOI=10.1145/1978942.1979042

37. Alexander  Thayer,  Matthew  J.  Bietz,  Katie  Derthick,
and  Charlotte  P.  Lee.  2012.  I  love  you,  let's  share
calendars:  calendar  sharing  as  relationship  work.  In
Proceedings of the ACM 2012 conference on Computer
Supported Cooperative Work (CSCW '12). ACM, New

York, 
DOI=10.1145/2145204.2145317 

NY, 

USA, 

749-758. 

38. Edward P. Thomson. 1971. The Moral Economy of the
English Crowd in the 18th Century. Past & Present 50
76-136.

39. Emily  Troshynski,  Charlotte  Lee,  and  Paul  Dourish.
2008. Accountabilities of presence: reframing location-
the  SIGCHI
based 
Conference  on  Human  Factors 
in  Computing
Systems (CHI  '08).  ACM,  New  York,  NY,  USA,  487-
496. DOI=10.1145/1357054.1357133

In Proceedings  of 

systems. 

40. Janet Vertesi and Paul Dourish. 2011. The value of data:
considering the context of production in data economies.
In Proceedings  of 
the  ACM  2011  conference  on
Computer  supported  cooperative  work (CSCW  '11).
ACM, 
533-542.
DOI=10.1145/1958824.1958906

York, 

USA, 

New 

NY, 

41. Theresa  Velden,  Matthew  J.  Bietz,  E.  Ilana  Diamant,
James  D.  Herbsleb,  James  Howison,  David  Ribes,  and
Stephanie  B.  Steinhardt.  2014.  Sharing,  re-use  and
circulation  of  resources  in  cooperative  scientific  work.
In Proceedings of the companion publication of the 17th
ACM  conference  on  Computer  supported  cooperative
work  &  social  computing  (CSCW  Companion  '14).
ACM, 
347-350.
DOI=10.1145/2556420.2558853

York, 

USA, 

New 

NY, 

42. Janet Vertesi. 2007. Mind the Gap: the London

Underground Map and Users’ Representations of Urban
Space. Social Studies of Science 38:1-36.

43. Jessica Vitak. 2012. “The Impact of Context Collapse
and Privacy on Social Network Site Disclosures.” J. of
Broadcasting & Electronic Media 56(4):451–70.

in:  practices  surrounding 

44. Amy  Voida,  Rebecca  E.  Grinter,  Nicolas  Ducheneaut,
W.  Keith  Edwards,  and  Mark  W.  Newman.  2005.
Listening 
iTunes  music
sharing.  In Proceedings  of  the  SIGCHI  Conference  on
Human Factors in Computing Systems (CHI '05). ACM,
New 
191-200.
DOI=10.1145/1054972.1054999

York, 

USA, 

NY, 

45. Amy Voida, Judith S. Olson, and Gary M. Olson. 2013.
Turbulence  in  the  clouds:  challenges  of  cloud-based
information  work.  In Proceedings  of 
the  SIGCHI
Conference  on  Human  Factors 
in  Computing
Systems (CHI  '13).  ACM,  New  York,  NY,  USA,  2273-
2282. DOI=10.1145/2470654.2481313

46. Laura Wynholds, David Fearon, Christine L. Borgman,
and  Sharon  Traweek.  2011.  Awash  in  stardust:  data
practices  in  astronomy.  In  Proceedings  of  the  2011
iConference  (iConference  '11).  ACM,  New  York,  NY,
USA, 802-804. DOI=10.1145/1940761.1940912
47. Viviana Zelizer. 2007. The Purchase of Intimacy.

Princeton University Press.

490

